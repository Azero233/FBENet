{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e0cfefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, models, datasets\n",
    "import imageio\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b953d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): Sequential(\n",
       "      (encoder_layer_0): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_1): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_2): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_3): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_4): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_5): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_6): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_7): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_8): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_9): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_10): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_11): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate=none)\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (heads): Sequential(\n",
       "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "\n",
    "model_ft = models.vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b3b18e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = model_ft.encoder.layers.encoder_layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9c9f5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderBlock(\n",
       "  (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (self_attention): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (mlp): MLPBlock(\n",
       "    (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (1): GELU(approximate=none)\n",
       "    (2): Dropout(p=0.0, inplace=False)\n",
       "    (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (4): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a2b98b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((3,4,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf5223f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.8423e-01, 2.9871e-01],\n",
       "         [9.6898e-03, 3.9235e-01],\n",
       "         [9.6691e-01, 6.4499e-02],\n",
       "         [8.7230e-01, 1.9455e-01]],\n",
       "\n",
       "        [[3.2413e-01, 6.5952e-01],\n",
       "         [9.4883e-01, 3.6410e-01],\n",
       "         [3.8010e-04, 4.2351e-01],\n",
       "         [7.5056e-01, 4.1600e-02]],\n",
       "\n",
       "        [[9.3843e-01, 6.2742e-01],\n",
       "         [2.2616e-01, 7.7219e-02],\n",
       "         [5.0713e-01, 3.6874e-01],\n",
       "         [4.3176e-01, 7.9782e-01]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "639490b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.flatten(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f05be4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6463, 0.2396],\n",
       "         [0.1683, 0.6769],\n",
       "         [0.4322, 0.3274],\n",
       "         [0.3627, 0.9635]],\n",
       "\n",
       "        [[0.2609, 0.3613],\n",
       "         [0.6049, 0.6662],\n",
       "         [0.1030, 0.4053],\n",
       "         [0.5458, 0.6204]],\n",
       "\n",
       "        [[0.6757, 0.5351],\n",
       "         [0.6667, 0.7874],\n",
       "         [0.4936, 0.9396],\n",
       "         [0.5432, 0.4118]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6300990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c9f3a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = torch.nn.Linear(2,5)\n",
    "a = layer(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8da935d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (4) must match the existing size (2) at non-singleton dimension 2.  Target sizes: [3, 4, 4].  Tensor sizes: [3, 4, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (4) must match the existing size (2) at non-singleton dimension 2.  Target sizes: [3, 4, 4].  Tensor sizes: [3, 4, 2]"
     ]
    }
   ],
   "source": [
    "a.expand(3,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69482747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.8423e-01, 2.9871e-01],\n",
       "         [9.6898e-03, 3.9235e-01],\n",
       "         [9.6691e-01, 6.4499e-02],\n",
       "         [8.7230e-01, 1.9455e-01]],\n",
       "\n",
       "        [[3.2413e-01, 6.5952e-01],\n",
       "         [9.4883e-01, 3.6410e-01],\n",
       "         [3.8010e-04, 4.2351e-01],\n",
       "         [7.5056e-01, 4.1600e-02]],\n",
       "\n",
       "        [[9.3843e-01, 6.2742e-01],\n",
       "         [2.2616e-01, 7.7219e-02],\n",
       "         [5.0713e-01, 3.6874e-01],\n",
       "         [4.3176e-01, 7.9782e-01]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adf1a21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4842, 0.2987],\n",
       "        [0.3241, 0.6595],\n",
       "        [0.9384, 0.6274]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22e7b6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.8635, 0.5002, 0.1439, 0.1032],\n",
       "          [0.9066, 0.6421, 0.1709, 0.9687],\n",
       "          [0.7331, 0.8476, 0.8797, 0.2761],\n",
       "          [0.9224, 0.0965, 0.4081, 0.2961]],\n",
       "\n",
       "         [[0.0978, 0.3826, 0.2653, 0.9337],\n",
       "          [0.2563, 0.2839, 0.1476, 0.5878],\n",
       "          [0.2795, 0.6101, 0.0238, 0.2841],\n",
       "          [0.5997, 0.1496, 0.3409, 0.2788]],\n",
       "\n",
       "         [[0.6217, 0.3742, 0.6077, 0.5569],\n",
       "          [0.4286, 0.0361, 0.5856, 0.7821],\n",
       "          [0.1564, 0.1503, 0.8068, 0.6646],\n",
       "          [0.7122, 0.2477, 0.1872, 0.6504]]],\n",
       "\n",
       "\n",
       "        [[[0.5732, 0.6409, 0.6194, 0.4930],\n",
       "          [0.8259, 0.1419, 0.4911, 0.1284],\n",
       "          [0.4421, 0.1239, 0.3021, 0.3016],\n",
       "          [0.7824, 0.0575, 0.0030, 0.1146]],\n",
       "\n",
       "         [[0.3798, 0.2149, 0.9618, 0.8657],\n",
       "          [0.0445, 0.6939, 0.4548, 0.2533],\n",
       "          [0.1739, 0.0527, 0.1283, 0.0213],\n",
       "          [0.9015, 0.3030, 0.4513, 0.1097]],\n",
       "\n",
       "         [[0.7332, 0.1255, 0.9010, 0.7605],\n",
       "          [0.6820, 0.1031, 0.0120, 0.5042],\n",
       "          [0.7068, 0.1906, 0.5986, 0.5296],\n",
       "          [0.3359, 0.4032, 0.5941, 0.9278]]],\n",
       "\n",
       "\n",
       "        [[[0.9775, 0.3827, 0.0925, 0.1231],\n",
       "          [0.6012, 0.1507, 0.2659, 0.3024],\n",
       "          [0.9445, 0.7432, 0.5079, 0.1643],\n",
       "          [0.4792, 0.3479, 0.9166, 0.8484]],\n",
       "\n",
       "         [[0.4749, 0.1996, 0.1880, 0.4774],\n",
       "          [0.4887, 0.3303, 0.6372, 0.3426],\n",
       "          [0.6548, 0.0693, 0.8113, 0.4740],\n",
       "          [0.2428, 0.4150, 0.7817, 0.5163]],\n",
       "\n",
       "         [[0.2684, 0.6127, 0.1261, 0.8691],\n",
       "          [0.5460, 0.4701, 0.7504, 0.1350],\n",
       "          [0.0217, 0.9062, 0.3927, 0.2505],\n",
       "          [0.8003, 0.0154, 0.8922, 0.5322]]],\n",
       "\n",
       "\n",
       "        [[[0.2414, 0.4164, 0.2031, 0.8864],\n",
       "          [0.3067, 0.5674, 0.5983, 0.7218],\n",
       "          [0.1916, 0.4196, 0.8408, 0.6931],\n",
       "          [0.7733, 0.7738, 0.5058, 0.5687]],\n",
       "\n",
       "         [[0.7909, 0.8032, 0.6331, 0.5981],\n",
       "          [0.8990, 0.7991, 0.5924, 0.5136],\n",
       "          [0.3799, 0.4033, 0.2737, 0.8390],\n",
       "          [0.9979, 0.8755, 0.5351, 0.0318]],\n",
       "\n",
       "         [[0.1380, 0.5418, 0.4259, 0.8790],\n",
       "          [0.9923, 0.6950, 0.0533, 0.5913],\n",
       "          [0.1392, 0.1827, 0.9449, 0.0909],\n",
       "          [0.6896, 0.1596, 0.2814, 0.0468]]],\n",
       "\n",
       "\n",
       "        [[[0.2789, 0.5894, 0.3003, 0.1795],\n",
       "          [0.6018, 0.6205, 0.3769, 0.1839],\n",
       "          [0.9679, 0.5565, 0.4301, 0.4514],\n",
       "          [0.5946, 0.3848, 0.5522, 0.7575]],\n",
       "\n",
       "         [[0.9195, 0.9565, 0.7391, 0.4175],\n",
       "          [0.6428, 0.3907, 0.1514, 0.7277],\n",
       "          [0.3895, 0.1470, 0.2853, 0.8235],\n",
       "          [0.0934, 0.6202, 0.7936, 0.4669]],\n",
       "\n",
       "         [[0.8074, 0.6040, 0.4154, 0.0704],\n",
       "          [0.9564, 0.7243, 0.8190, 0.5225],\n",
       "          [0.6740, 0.7844, 0.0595, 0.3551],\n",
       "          [0.4546, 0.1954, 0.1796, 0.3796]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand((5,3,4,4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "227b48be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5637],\n",
       "         [0.5764],\n",
       "         [0.5155],\n",
       "         [0.4508],\n",
       "         [0.4349],\n",
       "         [0.5633],\n",
       "         [0.5579],\n",
       "         [0.4748],\n",
       "         [0.5326],\n",
       "         [0.4604],\n",
       "         [0.5781],\n",
       "         [0.4698],\n",
       "         [0.4951],\n",
       "         [0.5483],\n",
       "         [0.5203],\n",
       "         [0.3609],\n",
       "         [0.5339],\n",
       "         [0.5418],\n",
       "         [0.5116],\n",
       "         [0.5037],\n",
       "         [0.5415],\n",
       "         [0.5537],\n",
       "         [0.4525],\n",
       "         [0.5982],\n",
       "         [0.4709],\n",
       "         [0.4805],\n",
       "         [0.4468],\n",
       "         [0.5511],\n",
       "         [0.4794],\n",
       "         [0.5141],\n",
       "         [0.5388],\n",
       "         [0.5129]],\n",
       "\n",
       "        [[0.4890],\n",
       "         [0.5022],\n",
       "         [0.4773],\n",
       "         [0.4713],\n",
       "         [0.5456],\n",
       "         [0.5961],\n",
       "         [0.4385],\n",
       "         [0.3769],\n",
       "         [0.5361],\n",
       "         [0.4640],\n",
       "         [0.4213],\n",
       "         [0.5196],\n",
       "         [0.5327],\n",
       "         [0.4769],\n",
       "         [0.5111],\n",
       "         [0.5146],\n",
       "         [0.5663],\n",
       "         [0.4605],\n",
       "         [0.4607],\n",
       "         [0.5077],\n",
       "         [0.5779],\n",
       "         [0.3992],\n",
       "         [0.5241],\n",
       "         [0.4489],\n",
       "         [0.5235],\n",
       "         [0.4927],\n",
       "         [0.5268],\n",
       "         [0.5699],\n",
       "         [0.5101],\n",
       "         [0.4966],\n",
       "         [0.4854],\n",
       "         [0.4601]],\n",
       "\n",
       "        [[0.5208],\n",
       "         [0.4928],\n",
       "         [0.5051],\n",
       "         [0.3944],\n",
       "         [0.5384],\n",
       "         [0.4538],\n",
       "         [0.5894],\n",
       "         [0.4825],\n",
       "         [0.5300],\n",
       "         [0.4778],\n",
       "         [0.5972],\n",
       "         [0.5431],\n",
       "         [0.5762],\n",
       "         [0.4971],\n",
       "         [0.4833],\n",
       "         [0.4546],\n",
       "         [0.4630],\n",
       "         [0.5239],\n",
       "         [0.4678],\n",
       "         [0.5822],\n",
       "         [0.4760],\n",
       "         [0.5173],\n",
       "         [0.4798],\n",
       "         [0.4905],\n",
       "         [0.4581],\n",
       "         [0.5156],\n",
       "         [0.4604],\n",
       "         [0.5787],\n",
       "         [0.4790],\n",
       "         [0.4900],\n",
       "         [0.4288],\n",
       "         [0.5251]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.mean(a, 2, True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12b01f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3444c8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.mean(a, 1, True)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da825ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5104]],\n",
       "\n",
       "        [[0.4964]],\n",
       "\n",
       "        [[0.5023]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0019bb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3,3,1,1,0,bias=True)\n",
    "bn = nn.BatchNorm2d(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff93c651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = conv(a)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f165427",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected 4D input (got 3D input)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m a\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:135\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_input_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# exponential_average_factor is set to self.momentum\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;66;03m# (when it is available) only so that it gets updated\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# in ONNX graph when this node is exported to ONNX.\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:407\u001b[0m, in \u001b[0;36mBatchNorm2d._check_input_dim\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_input_dim\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected 4D input (got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124mD input)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()))\n",
      "\u001b[1;31mValueError\u001b[0m: expected 4D input (got 3D input)"
     ]
    }
   ],
   "source": [
    "a = bn(a)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b36ac42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "a = ap(a)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7adc3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.5474]],\n",
       "\n",
       "         [[0.3451]],\n",
       "\n",
       "         [[0.4730]]],\n",
       "\n",
       "\n",
       "        [[[0.3776]],\n",
       "\n",
       "         [[0.3757]],\n",
       "\n",
       "         [[0.5068]]],\n",
       "\n",
       "\n",
       "        [[[0.4905]],\n",
       "\n",
       "         [[0.4440]],\n",
       "\n",
       "         [[0.4743]]],\n",
       "\n",
       "\n",
       "        [[[0.5442]],\n",
       "\n",
       "         [[0.6229]],\n",
       "\n",
       "         [[0.4282]]],\n",
       "\n",
       "\n",
       "        [[[0.4891]],\n",
       "\n",
       "         [[0.5353]],\n",
       "\n",
       "         [[0.5001]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97e59f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 4, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.nn.functional.interpolate(a, size=(4,4), mode='bilinear', align_corners=False) \n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fa0ab5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.5474, 0.5474, 0.5474, 0.5474],\n",
       "          [0.5474, 0.5474, 0.5474, 0.5474],\n",
       "          [0.5474, 0.5474, 0.5474, 0.5474],\n",
       "          [0.5474, 0.5474, 0.5474, 0.5474]],\n",
       "\n",
       "         [[0.3451, 0.3451, 0.3451, 0.3451],\n",
       "          [0.3451, 0.3451, 0.3451, 0.3451],\n",
       "          [0.3451, 0.3451, 0.3451, 0.3451],\n",
       "          [0.3451, 0.3451, 0.3451, 0.3451]],\n",
       "\n",
       "         [[0.4730, 0.4730, 0.4730, 0.4730],\n",
       "          [0.4730, 0.4730, 0.4730, 0.4730],\n",
       "          [0.4730, 0.4730, 0.4730, 0.4730],\n",
       "          [0.4730, 0.4730, 0.4730, 0.4730]]],\n",
       "\n",
       "\n",
       "        [[[0.3776, 0.3776, 0.3776, 0.3776],\n",
       "          [0.3776, 0.3776, 0.3776, 0.3776],\n",
       "          [0.3776, 0.3776, 0.3776, 0.3776],\n",
       "          [0.3776, 0.3776, 0.3776, 0.3776]],\n",
       "\n",
       "         [[0.3757, 0.3757, 0.3757, 0.3757],\n",
       "          [0.3757, 0.3757, 0.3757, 0.3757],\n",
       "          [0.3757, 0.3757, 0.3757, 0.3757],\n",
       "          [0.3757, 0.3757, 0.3757, 0.3757]],\n",
       "\n",
       "         [[0.5068, 0.5068, 0.5068, 0.5068],\n",
       "          [0.5068, 0.5068, 0.5068, 0.5068],\n",
       "          [0.5068, 0.5068, 0.5068, 0.5068],\n",
       "          [0.5068, 0.5068, 0.5068, 0.5068]]],\n",
       "\n",
       "\n",
       "        [[[0.4905, 0.4905, 0.4905, 0.4905],\n",
       "          [0.4905, 0.4905, 0.4905, 0.4905],\n",
       "          [0.4905, 0.4905, 0.4905, 0.4905],\n",
       "          [0.4905, 0.4905, 0.4905, 0.4905]],\n",
       "\n",
       "         [[0.4440, 0.4440, 0.4440, 0.4440],\n",
       "          [0.4440, 0.4440, 0.4440, 0.4440],\n",
       "          [0.4440, 0.4440, 0.4440, 0.4440],\n",
       "          [0.4440, 0.4440, 0.4440, 0.4440]],\n",
       "\n",
       "         [[0.4743, 0.4743, 0.4743, 0.4743],\n",
       "          [0.4743, 0.4743, 0.4743, 0.4743],\n",
       "          [0.4743, 0.4743, 0.4743, 0.4743],\n",
       "          [0.4743, 0.4743, 0.4743, 0.4743]]],\n",
       "\n",
       "\n",
       "        [[[0.5442, 0.5442, 0.5442, 0.5442],\n",
       "          [0.5442, 0.5442, 0.5442, 0.5442],\n",
       "          [0.5442, 0.5442, 0.5442, 0.5442],\n",
       "          [0.5442, 0.5442, 0.5442, 0.5442]],\n",
       "\n",
       "         [[0.6229, 0.6229, 0.6229, 0.6229],\n",
       "          [0.6229, 0.6229, 0.6229, 0.6229],\n",
       "          [0.6229, 0.6229, 0.6229, 0.6229],\n",
       "          [0.6229, 0.6229, 0.6229, 0.6229]],\n",
       "\n",
       "         [[0.4282, 0.4282, 0.4282, 0.4282],\n",
       "          [0.4282, 0.4282, 0.4282, 0.4282],\n",
       "          [0.4282, 0.4282, 0.4282, 0.4282],\n",
       "          [0.4282, 0.4282, 0.4282, 0.4282]]],\n",
       "\n",
       "\n",
       "        [[[0.4891, 0.4891, 0.4891, 0.4891],\n",
       "          [0.4891, 0.4891, 0.4891, 0.4891],\n",
       "          [0.4891, 0.4891, 0.4891, 0.4891],\n",
       "          [0.4891, 0.4891, 0.4891, 0.4891]],\n",
       "\n",
       "         [[0.5353, 0.5353, 0.5353, 0.5353],\n",
       "          [0.5353, 0.5353, 0.5353, 0.5353],\n",
       "          [0.5353, 0.5353, 0.5353, 0.5353],\n",
       "          [0.5353, 0.5353, 0.5353, 0.5353]],\n",
       "\n",
       "         [[0.5001, 0.5001, 0.5001, 0.5001],\n",
       "          [0.5001, 0.5001, 0.5001, 0.5001],\n",
       "          [0.5001, 0.5001, 0.5001, 0.5001],\n",
       "          [0.5001, 0.5001, 0.5001, 0.5001]]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26df6dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adfd1e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = torch.nn.Conv1d(\n",
    "            in_channels=3,\n",
    "            out_channels=10,\n",
    "            kernel_size=16,\n",
    "            stride=8,\n",
    "            padding=8,\n",
    "            bias=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e728f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(3,3,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cde291d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03d99881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "a = conv1(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "07b11c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _align_num_frames_with_strides(input: torch.Tensor, enc_kernel_size=16, enc_stride=8):\n",
    "        batch_size, num_channels, num_frames = input.shape\n",
    "        is_odd = enc_kernel_size % 2\n",
    "        num_strides = (num_frames - is_odd) // enc_stride\n",
    "        num_remainings = num_frames - (is_odd + num_strides * enc_stride)\n",
    "        if num_remainings == 0:\n",
    "            return input, 0\n",
    "\n",
    "        num_paddings = enc_stride - num_remainings\n",
    "        pad = torch.zeros(\n",
    "            batch_size,\n",
    "            num_channels,\n",
    "            num_paddings,\n",
    "            dtype=input.dtype,\n",
    "            device=input.device,\n",
    "        )\n",
    "        return torch.cat([input, pad], 2), num_paddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1706363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b,c = _align_num_frames_with_strides(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b6268e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 24])\n"
     ]
    }
   ],
   "source": [
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "217a9439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 10, 4])\n"
     ]
    }
   ],
   "source": [
    "b = conv1(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b286d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "feats = torch.randn(2,1,3)\n",
    "feats = feats.unsqueeze(1)\n",
    "print(feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2028511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2,2)\n",
    "b = torch.randn(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0ea577f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3700,  0.0180],\n",
      "        [ 0.4153, -1.3471]])\n"
     ]
    }
   ],
   "source": [
    "print(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a9158df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "import torch\n",
    "\n",
    "\n",
    "class ConvBlock(torch.nn.Module):\n",
    "    \"\"\"1D Convolutional block.\n",
    "\n",
    "    Args:\n",
    "        io_channels (int): The number of input/output channels, <B, Sc>\n",
    "        hidden_channels (int): The number of channels in the internal layers, <H>.\n",
    "        kernel_size (int): The convolution kernel size of the middle layer, <P>.\n",
    "        padding (int): Padding value of the convolution in the middle layer.\n",
    "        dilation (int, optional): Dilation value of the convolution in the middle layer.\n",
    "        no_redisual (bool, optional): Disable residual block/output.\n",
    "\n",
    "    Note:\n",
    "        This implementation corresponds to the \"non-causal\" setting in the paper.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        io_channels: int,\n",
    "        hidden_channels: int,\n",
    "        kernel_size: int,\n",
    "        padding: int,\n",
    "        dilation: int = 1,\n",
    "        no_residual: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_layers = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=io_channels, out_channels=hidden_channels, kernel_size=1),\n",
    "            torch.nn.PReLU(),\n",
    "            torch.nn.GroupNorm(num_groups=1, num_channels=hidden_channels, eps=1e-08),\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels=hidden_channels,\n",
    "                out_channels=hidden_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                padding=padding,\n",
    "                dilation=dilation,\n",
    "                groups=hidden_channels,\n",
    "            ),\n",
    "            torch.nn.PReLU(),\n",
    "            torch.nn.GroupNorm(num_groups=1, num_channels=hidden_channels, eps=1e-08),\n",
    "        )\n",
    "\n",
    "        self.res_out = (\n",
    "            None\n",
    "            if no_residual\n",
    "            else torch.nn.Conv1d(in_channels=hidden_channels, out_channels=io_channels, kernel_size=1)\n",
    "        )\n",
    "        self.skip_out = torch.nn.Conv1d(in_channels=hidden_channels, out_channels=io_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> Tuple[Optional[torch.Tensor], torch.Tensor]:\n",
    "        feature = self.conv_layers(input)\n",
    "        if self.res_out is None:\n",
    "            residual = None\n",
    "        else:\n",
    "            residual = self.res_out(feature)\n",
    "        skip_out = self.skip_out(feature)\n",
    "        return residual, skip_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7de0a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskGenerator(torch.nn.Module):\n",
    "    \"\"\"TCN (Temporal Convolution Network) Separation Module\n",
    "\n",
    "    Generates masks for separation.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): Input feature dimension, <N>.\n",
    "        num_sources (int): The number of sources to separate.\n",
    "        kernel_size (int): The convolution kernel size of conv blocks, <P>.\n",
    "        num_featrs (int): Input/output feature dimenstion of conv blocks, <B, Sc>.\n",
    "        num_hidden (int): Intermediate feature dimention of conv blocks, <H>\n",
    "        num_layers (int): The number of conv blocks in one stack, <X>.\n",
    "        num_stacks (int): The number of conv block stacks, <R>.\n",
    "        msk_activate (str): The activation function of the mask output.\n",
    "\n",
    "    Note:\n",
    "        This implementation corresponds to the \"non-causal\" setting in the paper.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        num_sources: int,\n",
    "        kernel_size: int,\n",
    "        num_feats: int,\n",
    "        num_hidden: int,\n",
    "        num_layers: int,\n",
    "        num_stacks: int,\n",
    "        msk_activate: str,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.num_sources = num_sources\n",
    "\n",
    "        self.input_norm = torch.nn.GroupNorm(num_groups=1, num_channels=input_dim, eps=1e-8)\n",
    "        self.input_conv = torch.nn.Conv1d(in_channels=input_dim, out_channels=num_feats, kernel_size=1)\n",
    "\n",
    "        self.receptive_field = 0\n",
    "        self.conv_layers = torch.nn.ModuleList([])\n",
    "        for s in range(num_stacks):\n",
    "            for l in range(num_layers):\n",
    "                multi = 2**l\n",
    "                self.conv_layers.append(\n",
    "                    ConvBlock(\n",
    "                        io_channels=num_feats,\n",
    "                        hidden_channels=num_hidden,\n",
    "                        kernel_size=kernel_size,\n",
    "                        dilation=multi,\n",
    "                        padding=multi,\n",
    "                        # The last ConvBlock does not need residual\n",
    "                        no_residual=(l == (num_layers - 1) and s == (num_stacks - 1)),\n",
    "                    )\n",
    "                )\n",
    "                self.receptive_field += kernel_size if s == 0 and l == 0 else (kernel_size - 1) * multi\n",
    "        self.output_prelu = torch.nn.PReLU()\n",
    "        self.output_conv = torch.nn.Conv1d(\n",
    "            in_channels=num_feats,\n",
    "            out_channels=input_dim * num_sources,\n",
    "            kernel_size=1,\n",
    "        )\n",
    "        if msk_activate == \"sigmoid\":\n",
    "            self.mask_activate = torch.nn.Sigmoid()\n",
    "        elif msk_activate == \"relu\":\n",
    "            self.mask_activate = torch.nn.ReLU()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation {msk_activate}\")\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Generate separation mask.\n",
    "\n",
    "        Args:\n",
    "            input (torch.Tensor): 3D Tensor with shape [batch, features, frames]\n",
    "\n",
    "        Returns:\n",
    "            Tensor: shape [batch, num_sources, features, frames]\n",
    "        \"\"\"\n",
    "        batch_size = input.shape[0]\n",
    "        feats = self.input_norm(input)\n",
    "        feats = self.input_conv(feats)\n",
    "        output = 0.0\n",
    "        for layer in self.conv_layers:\n",
    "            residual, skip = layer(feats)\n",
    "            if residual is not None:  # the last conv layer does not produce residual\n",
    "                feats = feats + residual\n",
    "            output = output + skip\n",
    "        output = self.output_prelu(output)\n",
    "        output = self.output_conv(output)\n",
    "        output = self.mask_activate(output)\n",
    "        return output.view(batch_size, self.num_sources, self.input_dim, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9d033c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sources = 2\n",
    "        # encoder/decoder parameters\n",
    "enc_kernel_size = 16\n",
    "enc_num_feats = 512\n",
    "        # mask generator parameters\n",
    "msk_kernel_size = 3\n",
    "msk_num_feats = 128\n",
    "msk_num_hidden_feats = 512\n",
    "msk_num_layers = 8\n",
    "msk_num_stacks = 3\n",
    "msk_activate = \"sigmoid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ad3e24fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sources = num_sources\n",
    "enc_num_feats = enc_num_feats\n",
    "enc_kernel_size = enc_kernel_size\n",
    "enc_stride = enc_kernel_size // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1a7a4f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(enc_stride)\n",
    "# //表示整除（向下取整）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2a070ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = torch.nn.Conv1d(\n",
    "            in_channels=1,\n",
    "            out_channels=enc_num_feats,\n",
    "            kernel_size=enc_kernel_size,\n",
    "            stride=enc_stride,\n",
    "            padding=enc_stride,\n",
    "            bias=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "42e5ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_generator = MaskGenerator(\n",
    "            input_dim=enc_num_feats,\n",
    "            num_sources=num_sources,\n",
    "            kernel_size=msk_kernel_size,\n",
    "            num_feats=msk_num_feats,\n",
    "            num_hidden=msk_num_hidden_feats,\n",
    "            num_layers=msk_num_layers,\n",
    "            num_stacks=msk_num_stacks,\n",
    "            msk_activate=msk_activate,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4317387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = torch.nn.ConvTranspose1d(\n",
    "            in_channels=enc_num_feats,\n",
    "            out_channels=1,\n",
    "            kernel_size=enc_kernel_size,\n",
    "            stride=enc_stride,\n",
    "            padding=enc_stride,\n",
    "            bias=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "71eeab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(10,1,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4a154135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 1000])\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "padded, num_pads = _align_num_frames_with_strides(input)\n",
    "print(padded.shape)\n",
    "print(num_pads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "70f543e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "batch_size, num_padded_frames = padded.shape[0], padded.shape[2]\n",
    "print(batch_size)\n",
    "print(num_padded_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f11c0a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 512, 126])\n"
     ]
    }
   ],
   "source": [
    "feats = encoder(padded)\n",
    "print(feats.shape)\n",
    "# 输出为# batchsize, 分频率, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "380d9a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2, 512, 126])\n"
     ]
    }
   ],
   "source": [
    "masked1 = mask_generator(feats)\n",
    "print(masked1.shape)\n",
    "# B, S, F, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "110e9911",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = feats.unsqueeze(1)\n",
    "print(feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cb7ab3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2, 512, 126])\n"
     ]
    }
   ],
   "source": [
    "masked = masked1 * feats  # *为对应元素相乘，@为矩阵乘，此处为对应元素乘，F和M的维度必须一样\n",
    "print(masked.shape)\n",
    "# B, S, F, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f3228cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 512, 126])\n"
     ]
    }
   ],
   "source": [
    "masked = masked.view(batch_size * num_sources, enc_num_feats, -1)\n",
    "print(masked.shape)\n",
    "# B*S, F, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "036d52dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 1000])\n"
     ]
    }
   ],
   "source": [
    "decoded = decoder(masked)\n",
    "print(decoded.shape)\n",
    "# B*S, 1, L'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "df8e827f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2, 1000])\n"
     ]
    }
   ],
   "source": [
    "output = decoded.view(batch_size, num_sources, num_padded_frames)\n",
    "print(output.shape)\n",
    "# B, S, L'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bc19714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_pads > 0:\n",
    "    output = output[..., :-num_pads]\n",
    "# B, S, L\n",
    "# 这一步将填充的pads去掉"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e079beef",
   "metadata": {},
   "source": [
    "太神奇啦，居然能将输入和输出的维度对上！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a38ea43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "报名files: ['CCF广东工业大学学生分会换届大会暨”智能影像分析技术与案例研讨“学术专题讲座-.xls']\n",
      "0       True\n",
      "1       True\n",
      "2       True\n",
      "3       True\n",
      "4       True\n",
      "       ...  \n",
      "313     True\n",
      "314    False\n",
      "315    False\n",
      "316    False\n",
      "317    False\n",
      "Name: 姓名, Length: 318, dtype: bool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\54469\\AppData\\Local\\Temp\\ipykernel_13352\\3487757190.py:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_data = new_data.append(add_data_pd)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "时间：2022/10/19\n",
    "作者：余俊锐\n",
    "审查：余俊锐\n",
    "版权归属：广工计算机研学会学术部\n",
    "使用说明： 在方法上创建工作路径，命名按第几期进行命名，创建文件夹‘报名名单’和‘结果’，分别\n",
    "        ‘第x期’中放置需要添加的人员名单，列名【姓名，学号】\n",
    "        ‘报名名单’中放置报名工具生成的名单，需要将标题删除后再使用\n",
    "        ‘结果’为最后生成的数据，点击打开后，重新保存，因为有可能出现格式错误，重新保存可以解决\n",
    "        方法增加了学号校验，学院校验\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    该文件用于报名工具名单的人员处理\n",
    "    1、创建对应期数的文件夹作为工作路径，修改工作路径\n",
    "    2、在对应工作路径下创建 报名名单 和 结果 文件夹\n",
    "    3、在报名名单下添加 报名文件\n",
    "    4、如果有额外添加的人员，新建excel文件放置在work_path路径下，列名为【姓名，学号】\n",
    "    5、筛选结果人数为len_people\n",
    "    6、使用前先将非本学院的人从报名工具当中去除\n",
    "    \"\"\"\n",
    "    # -------------------- 参数设置------------------------\n",
    "    '''工作路径'''\n",
    "    work_path = r\"C:\\Users\\54469\\Desktop\"\n",
    "    '''报名名单的相对路径，将读取该路径下的文件作为报名的文件的路径'''\n",
    "    sign_path = '{}/报名名单'.format(work_path)\n",
    "    '''导出会议名单相对路径'''\n",
    "    out_path = '{}/结果'.format(work_path)\n",
    "    '''截取人数'''\n",
    "    len_people = 150\n",
    "\n",
    "    # -------------------处理报名名单----------------------\n",
    "    files = []\n",
    "    for index, file in enumerate(os.listdir(sign_path)):  #\n",
    "        if file.endswith('.xls') and not file.startswith('公示名单'):\n",
    "            files.append(file)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    add_files = []\n",
    "    for index, file in enumerate(os.listdir(work_path)):  #\n",
    "        if file.endswith('.xls') and not file.startswith('公示名单'):\n",
    "            add_files.append(file)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    if len(files) == 0:\n",
    "        print('请在指定位置添加报名名单')\n",
    "    print('报名files: {}'.format(files))\n",
    "    '''xls文件处理'''\n",
    "    for file in files:\n",
    "        file_name = file.split(\"-\")  # 选择file_name 作为最后的文档名拼接\n",
    "        file = '{}/{}'.format(sign_path, file)\n",
    "        write = pd.ExcelWriter('{}/{}-报名公示.xlsx'.format(out_path, file_name[0]))\n",
    "        sign_up_list_data = pd.read_excel(file, engine='xlrd', dtype='object')\n",
    "        print(sign_up_list_data['姓名'].notnull())\n",
    "        null_pd = pd.DataFrame()\n",
    "        null_pd.to_excel(write, index=False, sheet_name=\"报名成功名单\")\n",
    "        null_pd.to_excel(write, index=False, sheet_name=\"筛选名单\")\n",
    "        sign_up_list_data.to_excel(write, index=False, sheet_name=\"原始数据\")\n",
    "        sign_up_list_data['随机数'] = 0\n",
    "        sign_up_list_data = sign_up_list_data[sign_up_list_data['姓名'].notnull()]\n",
    "        sign_up_list_data['学号'] = sign_up_list_data['学号'].astype(str)\n",
    "        sign_up_list_data['学号'] = sign_up_list_data['学号'].str.strip()\n",
    "        sign_up_list_data = sign_up_list_data[sign_up_list_data['学号'].str.startswith('2112')]\n",
    "        # sign_up_list_data = sign_up_list_data[sign_up_list_data['学院'].str.contains('计')]\n",
    "        sign_up_list_data['随机数'] = np.random.rand(len(sign_up_list_data['姓名']),1)\n",
    "        sign_up_list_data = sign_up_list_data.sort_values('随机数', ascending=False)\n",
    "        # sign_up_list_data.to_excel(write, columns=['姓名', '学号', '随机数'], index=False, sheet_name='筛选名单')\n",
    "        sign_up_list_data.to_excel(write, columns=['唯一编号', '昵称', '姓名', '学号', '学院', '随机数'], index=False, sheet_name=\"筛选名单\")\n",
    "        new_data = sign_up_list_data[0:len_people]\n",
    "        new_data = new_data.sort_values('学号')\n",
    "        # ----------添加额外人员----------\n",
    "        if len(add_files) != 0:\n",
    "            for add_file in add_files:\n",
    "                add_file = '{}/{}'.format(work_path, add_file)\n",
    "                add_data_pd = pd.read_excel(add_file, engine='xlrd', dtype='object')\n",
    "                add_data_pd['学号'] = add_data_pd['学号'].astype(str)\n",
    "                add_data_pd['学号'] = add_data_pd['学号'].str.strip()\n",
    "                new_data = new_data.append(add_data_pd)\n",
    "                new_data['学院'] = '计算机学院'\n",
    "        # ----------添加额外人员----------\n",
    "        new_data.to_excel(write, columns=['学号', '姓名', '学院', '随机数'], index=False, sheet_name=\"报名成功名单\")\n",
    "        write.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3399d3c9",
   "metadata": {},
   "source": [
    "简单的文件处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01369dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "38\n",
      "35\n",
      "49\n",
      "36\n",
      "68\n",
      "73\n",
      "38\n",
      "44\n",
      "38\n",
      "36\n",
      "60\n",
      "65\n",
      "38\n",
      "49\n",
      "46\n",
      "34\n",
      "47\n",
      "72\n",
      "35\n",
      "34\n",
      "33\n",
      "36\n",
      "55\n",
      "62\n",
      "36\n",
      "61\n",
      "48\n",
      "36\n",
      "31\n",
      "28\n",
      "33\n",
      "62\n",
      "92\n",
      "44\n",
      "33\n",
      "44\n",
      "54\n",
      "97\n",
      "49\n",
      "100\n",
      "73\n",
      "33\n",
      "157\n",
      "61\n",
      "57\n",
      "38\n",
      "54\n",
      "73\n",
      "206\n",
      "67\n",
      "70\n",
      "47\n",
      "56\n",
      "92\n",
      "50\n",
      "86\n",
      "56\n",
      "35\n",
      "85\n",
      "36\n",
      "48\n",
      "42\n",
      "42\n",
      "88\n",
      "51\n",
      "36\n",
      "43\n",
      "46\n",
      "33\n",
      "51\n",
      "64\n",
      "77\n",
      "147\n",
      "142\n",
      "95\n",
      "83\n",
      "205\n",
      "112\n",
      "34\n",
      "70\n",
      "82\n",
      "135\n",
      "82\n",
      "104\n",
      "66\n",
      "48\n",
      "48\n",
      "51\n",
      "116\n",
      "153\n",
      "41\n",
      "66\n",
      "59\n",
      "53\n",
      "34\n",
      "132\n",
      "101\n",
      "72\n",
      "54\n",
      "68\n",
      "50\n",
      "8\n",
      "4\n",
      "6\n",
      "5\n",
      "6\n",
      "10\n",
      "5\n",
      "5\n",
      "1\n",
      "7\n",
      "2\n",
      "16\n",
      "11\n",
      "4\n",
      "6\n",
      "7\n",
      "4\n",
      "8\n",
      "12\n",
      "5\n",
      "2\n",
      "3\n",
      "1\n",
      "5\n",
      "7\n",
      "2\n",
      "10\n",
      "2\n",
      "3\n",
      "7\n",
      "7\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "3\n",
      "6\n",
      "5\n",
      "16\n",
      "6\n",
      "14\n",
      "9\n",
      "4\n",
      "18\n",
      "3\n",
      "9\n",
      "8\n",
      "7\n",
      "11\n",
      "28\n",
      "10\n",
      "9\n",
      "10\n",
      "8\n",
      "9\n",
      "6\n",
      "14\n",
      "4\n",
      "1\n",
      "14\n",
      "6\n",
      "3\n",
      "8\n",
      "5\n",
      "7\n",
      "6\n",
      "2\n",
      "8\n",
      "5\n",
      "1\n",
      "7\n",
      "5\n",
      "8\n",
      "19\n",
      "15\n",
      "12\n",
      "20\n",
      "21\n",
      "11\n",
      "4\n",
      "5\n",
      "12\n",
      "18\n",
      "13\n",
      "13\n",
      "10\n",
      "5\n",
      "5\n",
      "6\n",
      "25\n",
      "16\n",
      "3\n",
      "2\n",
      "9\n",
      "2\n",
      "6\n",
      "14\n",
      "13\n",
      "10\n",
      "7\n",
      "10\n",
      "6\n",
      "7370\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "\n",
    "datadir = r\"E:\\myfile\\2022-2023\\各种奇怪的代码\\pytorch_tutorial\\028_034：图像识别核心模块实战解读\\卷积网络实战\\flower_data\"\n",
    "a = 0\n",
    "\n",
    "for i in os.listdir(datadir):\n",
    "    sdir = os.path.join(datadir, i)\n",
    "    for j in os.listdir(sdir):\n",
    "        tdir = os.path.join(sdir, j)\n",
    "        a += len(os.listdir(tdir))\n",
    "    print(a)\n",
    "print(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b312a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.25\n",
    "max_gamma=3\n",
    "num_classes=2\n",
    "size_average=True\n",
    "epoch=200\n",
    "split=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66319f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_split_span = epoch / split\n",
    "gamma_span = max_gamma / (split-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7de39aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_split_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03da8f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "549748e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 100, 150, 200]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_split = list(range(0, epoch, gamma_split_span))\n",
    "gamma_split = [*map(lambda x:x+gamma_split_span, gamma_split)]\n",
    "gamma_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1068f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.0, 3.0, 4.0]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = []\n",
    "gamma_split = []\n",
    "n = 0\n",
    "m = 0\n",
    "for i in range(split):\n",
    "    m += gamma_split_span\n",
    "    n += gamma_span\n",
    "    gamma.append(n)\n",
    "    gamma_split.append(m)\n",
    "    \n",
    "gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8f551927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50.0, 100.0, 150.0, 200.0]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a300f0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50.0\n",
      "1\n",
      "100.0\n",
      "2\n",
      "150.0\n",
      "3\n",
      "200.0\n"
     ]
    }
   ],
   "source": [
    "for i,n in enumerate(gamma_split):\n",
    "    print(i)\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b86977",
   "metadata": {},
   "source": [
    "空间注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1cc9158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=7, padding=7 // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        # 压缩通道提取空间信息\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        # 经过卷积提取空间注意力权重\n",
    "        x = torch.cat([max_out, avg_out], dim=1)\n",
    "        out = self.conv1(x)\n",
    "        # 输出非负\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bee4090e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.4608,  0.6083,  0.6780,  1.2978, -0.5806],\n",
       "          [ 0.8322, -0.3913,  0.2327,  1.1116,  0.0886],\n",
       "          [ 2.5856,  1.0699,  0.6909,  1.8917,  1.1411],\n",
       "          [-0.4727,  0.8836,  0.0776, -0.0390,  1.3603],\n",
       "          [-1.7871, -0.5773, -0.3445,  0.4017, -1.2424]],\n",
       "\n",
       "         [[-0.5791, -1.1577,  0.4284,  1.5596, -1.1020],\n",
       "          [ 0.5986, -1.8203,  0.5768,  0.2990, -1.4570],\n",
       "          [ 0.2605, -1.1725,  0.8634, -1.1953, -0.7474],\n",
       "          [-0.9153, -0.4563, -0.6334,  0.3975, -1.2407],\n",
       "          [-0.8747, -2.3684,  2.5104, -0.8198, -0.9196]],\n",
       "\n",
       "         [[ 0.4632,  0.0409,  0.7671, -1.0282, -1.6957],\n",
       "          [ 1.2146, -1.5956, -0.7351,  0.4318, -1.5435],\n",
       "          [ 2.2750, -0.3302, -0.7520, -0.3099, -0.3498],\n",
       "          [ 1.6909,  0.6941, -1.3569,  2.1984,  0.1538],\n",
       "          [-0.4788,  2.5777, -0.5045, -1.5407, -0.2768]]],\n",
       "\n",
       "\n",
       "        [[[-1.6690,  0.7950,  0.5913, -0.5904, -1.8864],\n",
       "          [-0.0899,  0.2393,  1.4223, -2.4186, -0.7062],\n",
       "          [ 1.4658, -1.6773, -1.8487, -0.1247,  0.9869],\n",
       "          [-1.7423, -1.5887,  1.1699, -0.1013,  0.4244],\n",
       "          [-0.9427,  0.4574,  1.2430,  0.0793, -1.3344]],\n",
       "\n",
       "         [[-1.7419,  0.2305,  0.5591,  0.9610, -0.8902],\n",
       "          [ 1.1297, -0.8282,  0.9454, -0.8961,  1.0973],\n",
       "          [ 1.4847, -0.7157, -0.5671, -2.1370, -0.4559],\n",
       "          [ 1.6581,  1.1561,  1.1948, -2.1600, -0.7287],\n",
       "          [ 0.4505,  0.9268,  0.2721,  0.4693, -1.4148]],\n",
       "\n",
       "         [[-0.8544,  0.8378, -0.1445, -1.3200, -0.2095],\n",
       "          [ 1.8809,  0.0558, -0.4670, -2.0093,  0.5088],\n",
       "          [ 1.6817, -0.4894, -0.4931,  0.4027, -1.1245],\n",
       "          [-0.8022,  2.1477,  0.5524, -0.2089, -0.2718],\n",
       "          [-0.6290, -1.0551, -0.0358, -0.4192,  1.4929]]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2,3,5,5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "895cc3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpatialAttention(\n",
       "  (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = SpatialAttention()\n",
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c89cdc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4239, 0.4664, 0.3596, 0.3945, 0.5226],\n",
       "          [0.2871, 0.3955, 0.3793, 0.3147, 0.5999],\n",
       "          [0.3946, 0.4530, 0.4554, 0.3876, 0.4538],\n",
       "          [0.3273, 0.4378, 0.5477, 0.4588, 0.4210],\n",
       "          [0.4779, 0.4016, 0.4806, 0.3932, 0.4439]]],\n",
       "\n",
       "\n",
       "        [[[0.4771, 0.5512, 0.4085, 0.4787, 0.5531],\n",
       "          [0.4732, 0.4148, 0.5022, 0.3442, 0.4558],\n",
       "          [0.3887, 0.5473, 0.4845, 0.5381, 0.3776],\n",
       "          [0.3570, 0.4914, 0.4468, 0.5896, 0.4642],\n",
       "          [0.4307, 0.4269, 0.5480, 0.4001, 0.3856]]]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = sp(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "181eb5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5, 5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba02d260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a * b\n",
    "c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e2f22d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0818,  0.6467, -0.5399, -0.1180, -0.7981],\n",
       "          [-0.3033,  0.6890,  0.7490,  0.6174,  0.2510],\n",
       "          [ 0.0907, -0.5988,  0.1723, -0.2069,  0.1348],\n",
       "          [ 0.8769,  0.3614,  0.7397, -0.3258,  0.0577],\n",
       "          [-0.6559, -0.5409, -0.6703, -0.0847,  0.4660]],\n",
       "\n",
       "         [[-0.2667,  0.0308, -0.0726, -0.3346, -0.0209],\n",
       "          [ 0.4650,  0.8673,  0.4554,  0.2898,  0.2319],\n",
       "          [ 1.0282, -0.2046,  0.4887,  0.0196, -0.5363],\n",
       "          [-0.0701, -0.2793,  0.6749, -0.7656,  0.2678],\n",
       "          [-0.3965,  0.5835, -0.4100,  0.0703,  0.0817]],\n",
       "\n",
       "         [[-0.3808,  0.1436, -0.7972,  0.3561, -0.1837],\n",
       "          [ 0.4568,  0.2451, -0.0555,  0.6382,  0.1721],\n",
       "          [ 0.0077, -0.1413, -0.3243, -0.2507, -0.5343],\n",
       "          [ 0.0936,  0.0061,  0.2226, -0.5326, -1.1568],\n",
       "          [-0.6950,  0.3353, -0.0165,  0.0246,  0.7882]]],\n",
       "\n",
       "\n",
       "        [[[ 0.6962,  0.5488, -0.6768, -0.2350,  0.4656],\n",
       "          [-1.2748,  0.7762, -0.0516, -0.7424, -0.1041],\n",
       "          [ 0.5736, -0.3360, -0.2387, -0.3717,  0.0316],\n",
       "          [-0.5997,  0.2406, -0.9155, -0.2965, -0.3582],\n",
       "          [ 0.2512,  0.3466,  0.4230, -0.2774, -0.0350]],\n",
       "\n",
       "         [[ 0.2939,  0.1515,  0.4608, -0.9087,  0.2751],\n",
       "          [-0.5986, -0.1839, -0.7025,  0.0490, -0.1844],\n",
       "          [ 1.1473, -0.6879,  1.2856, -0.2584, -0.2480],\n",
       "          [ 0.7516, -0.1025,  1.1745, -0.4598,  0.6068],\n",
       "          [-0.2679,  0.8688,  0.0549, -0.3510,  0.8441]],\n",
       "\n",
       "         [[ 0.1274, -0.2559, -0.2063,  0.3059, -0.1373],\n",
       "          [-0.0115, -0.6014,  0.3755, -0.0575,  0.1016],\n",
       "          [ 0.3753,  0.0093, -1.1776,  0.2722,  0.8482],\n",
       "          [ 0.2901, -0.1842,  0.2551, -0.1011, -0.5674],\n",
       "          [ 0.6875, -0.4934, -0.7638, -0.3021, -0.3911]]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5caeb562",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=7, padding=7 // 2, bias=False)\n",
    "sigmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b389a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_out, _ = torch.max(a, dim=1, keepdim=True)\n",
    "max_out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce66415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfbbc4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5, 5])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_out = torch.mean(a, dim=1, keepdim=True)\n",
    "avg_out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16d6f1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 5, 5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 经过卷积提取空间注意力权重\n",
    "x = torch.cat([max_out, avg_out], dim=1)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5bfbdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5, 5])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = conv1(x)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41d3591f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5, 5])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = sigmoid(out)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c7aa71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaptiveAvgPool2d(output_size=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap = torch.nn.AdaptiveAvgPool2d(1)\n",
    "ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47fbfa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = ap(a)\n",
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3db1a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5, 5])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.mean(a, dim=1, keepdim=True)\n",
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e073cf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(torch.nn.Module):\n",
    "    # 空间注意力\n",
    "    def __init__(\n",
    "            self,\n",
    "            activation = torch.nn.ReLU,\n",
    "            scale_activation = torch.nn.Sigmoid,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=7, padding=7 // 2, bias=False)\n",
    "        self.scale_activation = scale_activation()\n",
    "        self.activation = activation()\n",
    "\n",
    "    def _scale(self, x):\n",
    "        scale = torch.mean(x, dim=1, keepdim=True)  # 压缩通道，B,1,W,H\n",
    "        scale = self.activation(scale)              # 过激活函数，Swish\n",
    "        scale = self.conv1(scale)                   # 7*7卷积\n",
    "        return self.scale_activation(scale)         # 过S函数\n",
    "\n",
    "    def forward(self, x):\n",
    "        scale = self._scale(x)\n",
    "        return scale * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed7ea0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpatialAttention(\n",
       "  (conv1): Conv2d(1, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "  (scale_activation): Sigmoid()\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = SpatialAttention()\n",
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3af4f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.5286, -0.4347,  0.5691,  0.1707, -0.3151],\n",
       "          [ 0.4654,  0.5342,  0.7557,  0.2657,  2.0248],\n",
       "          [-0.6644, -0.2342,  0.4695,  0.8974,  0.2327],\n",
       "          [-0.9005, -1.3277,  0.8622, -2.1104, -0.9401],\n",
       "          [ 0.9488, -1.0526,  0.5012, -1.0522,  2.6167]],\n",
       "\n",
       "         [[-1.6506,  1.3244,  0.0674, -1.0445, -1.2324],\n",
       "          [-0.0399, -0.5837, -0.6501,  0.9812,  0.4808],\n",
       "          [-0.3467,  1.4414, -1.1650,  0.4514, -1.2616],\n",
       "          [ 0.6378,  1.9424, -1.7958,  0.8658,  0.4773],\n",
       "          [ 0.6408, -0.1609, -0.2765, -0.2740,  0.8477]],\n",
       "\n",
       "         [[ 0.3064, -1.7544, -0.5060, -0.6738,  1.8561],\n",
       "          [-0.1998,  0.6680,  1.2047,  1.3519, -0.7833],\n",
       "          [-0.6256, -1.5222, -0.1914, -0.7464, -0.0217],\n",
       "          [ 0.5127, -0.6052,  0.0545,  1.4577, -1.7289],\n",
       "          [-1.2410, -0.0642, -0.7631, -0.9726,  0.4959]]],\n",
       "\n",
       "\n",
       "        [[[ 0.5864, -0.3693,  0.1426,  1.4548, -2.0316],\n",
       "          [ 0.7912,  0.5848,  1.0839,  1.7743, -0.7303],\n",
       "          [ 0.8964, -1.9332, -0.9326,  0.2382,  0.4800],\n",
       "          [ 0.7492, -1.9870, -2.6343, -1.2498, -1.6129],\n",
       "          [ 0.8590, -0.0999, -1.9138, -0.6996, -0.2697]],\n",
       "\n",
       "         [[ 0.6047, -1.2092,  1.4380, -0.8041, -0.8909],\n",
       "          [ 1.1303, -1.0959,  0.2256,  2.2028,  1.1136],\n",
       "          [-0.3856,  1.1391, -0.5006, -0.3671,  1.8545],\n",
       "          [-1.2021,  0.4068,  1.1634, -1.2827, -0.3267],\n",
       "          [ 0.9864, -0.5660, -0.3202, -0.4801, -0.9590]],\n",
       "\n",
       "         [[-0.5476, -1.0196,  0.9486, -0.9875,  0.5816],\n",
       "          [-0.3881, -1.4309,  1.8038, -0.3413, -0.4274],\n",
       "          [ 0.4242,  0.4009, -0.2343,  0.6421, -0.6750],\n",
       "          [-0.2775,  1.3568,  0.2557, -0.0739, -0.1243],\n",
       "          [ 0.0982, -1.2993,  0.0497, -0.3184, -0.1235]]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2,3,5,5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13409905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5, 5])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = torch.mean(a, dim=1, keepdim=True)\n",
    "scale.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e362df95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5, 5])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu = torch.nn.ReLU()\n",
    "scale = relu(scale)\n",
    "scale.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9892c7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5, 5])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=7, padding=7 // 2, bias=False)\n",
    "scale = conv1(scale)\n",
    "scale.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05e53a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.nn.Sigmoid()\n",
    "scale = s(scale)\n",
    "scale.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7415c934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5, 5])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "572d769d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5, 5])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = scale * a\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2242aec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5, 5])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = sp(a)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7f2289",
   "metadata": {},
   "source": [
    "三层的空洞卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c8b89206",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1, dilation=1)\n",
    "conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=2, dilation=2)\n",
    "conv3 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=4, dilation=4)\n",
    "conv4 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=8, dilation=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1ffbc613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5, 5])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2,3,5,5)\n",
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aef35f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5, 5])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = conv1(a)\n",
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d1f92c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5, 5])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = conv2(b)\n",
    "c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f5109dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5, 5])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = conv3(c)\n",
    "d.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dbbd02d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5, 5])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = conv4(d)\n",
    "e.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "31797a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 5, 5])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.cat([b, c, d, e], dim=1)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ed1651",
   "metadata": {},
   "source": [
    "测试模型集成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3274332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1, bias=False)\n",
    "conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f01f8da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000001AD3251C2E0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f31fe62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.0613,  0.0534, -0.0373],\n",
      "          [-0.1193,  0.1856, -0.0455],\n",
      "          [-0.0191,  0.1048, -0.1513]],\n",
      "\n",
      "         [[-0.0080, -0.1112,  0.0291],\n",
      "          [ 0.1007,  0.0685,  0.0521],\n",
      "          [-0.1563,  0.1774, -0.1910]],\n",
      "\n",
      "         [[-0.1268, -0.0416,  0.0750],\n",
      "          [ 0.1187, -0.0324, -0.0876],\n",
      "          [ 0.1622,  0.1158,  0.0803]]],\n",
      "\n",
      "\n",
      "        [[[-0.1065,  0.1076,  0.0106],\n",
      "          [-0.0357, -0.1750, -0.1482],\n",
      "          [-0.0489, -0.0109,  0.0354]],\n",
      "\n",
      "         [[-0.1038, -0.0647,  0.0012],\n",
      "          [-0.1069, -0.1338, -0.1513],\n",
      "          [ 0.1417, -0.0964, -0.1218]],\n",
      "\n",
      "         [[ 0.1808,  0.0858,  0.0669],\n",
      "          [ 0.1528, -0.0935, -0.1912],\n",
      "          [ 0.1616, -0.0246,  0.1493]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1852,  0.0074,  0.0914],\n",
      "          [ 0.0126, -0.1117,  0.0093],\n",
      "          [ 0.1859, -0.1363,  0.1835]],\n",
      "\n",
      "         [[ 0.1081, -0.1156,  0.1336],\n",
      "          [ 0.0487,  0.1908,  0.1723],\n",
      "          [-0.1201,  0.0602, -0.1413]],\n",
      "\n",
      "         [[-0.0092, -0.1702, -0.0884],\n",
      "          [-0.0045, -0.1649, -0.1130],\n",
      "          [ 0.0650,  0.1039,  0.1158]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in conv1.parameters():\n",
    "    a = i\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "315fefd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 3, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5da5d2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 3, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in conv2.parameters():\n",
    "    b = i\n",
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "198fdf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.0949, -0.0326,  0.0070],\n",
       "          [ 0.1715, -0.0771,  0.1806],\n",
       "          [ 0.0424,  0.1182,  0.1553]],\n",
       "\n",
       "         [[-0.0139,  0.0150,  0.1008],\n",
       "          [-0.1282, -0.0725, -0.1651],\n",
       "          [-0.1797,  0.1176,  0.1500]],\n",
       "\n",
       "         [[ 0.0359, -0.1809, -0.0233],\n",
       "          [ 0.0291, -0.1108, -0.1709],\n",
       "          [ 0.0474,  0.1575, -0.0795]]],\n",
       "\n",
       "\n",
       "        [[[-0.0592, -0.1730, -0.1429],\n",
       "          [ 0.1810, -0.0887, -0.0724],\n",
       "          [ 0.1291,  0.1172,  0.1442]],\n",
       "\n",
       "         [[ 0.0321,  0.0045, -0.1718],\n",
       "          [-0.0100,  0.0268, -0.1332],\n",
       "          [ 0.1294,  0.0101, -0.1216]],\n",
       "\n",
       "         [[ 0.1019,  0.0823, -0.0273],\n",
       "          [ 0.0560,  0.1742,  0.1505],\n",
       "          [-0.1627,  0.0174,  0.1565]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1098,  0.0660,  0.1221],\n",
       "          [ 0.1832,  0.1307, -0.0482],\n",
       "          [ 0.0217, -0.0561,  0.0732]],\n",
       "\n",
       "         [[-0.1410,  0.0575,  0.1152],\n",
       "          [ 0.0413, -0.0506, -0.1584],\n",
       "          [-0.0271,  0.0445, -0.0884]],\n",
       "\n",
       "         [[ 0.1182,  0.1396,  0.0886],\n",
       "          [ 0.0183, -0.0054,  0.1326],\n",
       "          [ 0.0241,  0.0072,  0.1594]]]], requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c0edef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 7.8101e-02,  1.0412e-02, -1.5171e-02],\n",
       "          [ 2.6091e-02,  5.4220e-02,  6.7543e-02],\n",
       "          [ 1.1616e-02,  1.1151e-01,  2.0059e-03]],\n",
       "\n",
       "         [[-1.0941e-02, -4.8102e-02,  6.4917e-02],\n",
       "          [-1.3779e-02, -2.0113e-03, -5.6515e-02],\n",
       "          [-1.6798e-01,  1.4748e-01, -2.0509e-02]],\n",
       "\n",
       "         [[-4.5459e-02, -1.1121e-01,  2.5882e-02],\n",
       "          [ 7.3860e-02, -7.1595e-02, -1.2922e-01],\n",
       "          [ 1.0478e-01,  1.3667e-01,  3.8619e-04]]],\n",
       "\n",
       "\n",
       "        [[[-8.2822e-02, -3.2692e-02, -6.6125e-02],\n",
       "          [ 7.2682e-02, -1.3185e-01, -1.1033e-01],\n",
       "          [ 4.0104e-02,  5.3166e-02,  8.9800e-02]],\n",
       "\n",
       "         [[-3.5824e-02, -3.0077e-02, -8.5321e-02],\n",
       "          [-5.8438e-02, -5.3528e-02, -1.4223e-01],\n",
       "          [ 1.3552e-01, -4.3111e-02, -1.2169e-01]],\n",
       "\n",
       "         [[ 1.4135e-01,  8.4033e-02,  1.9830e-02],\n",
       "          [ 1.0438e-01,  4.0369e-02, -2.0362e-02],\n",
       "          [-5.6192e-04, -3.6431e-03,  1.5290e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4749e-01,  3.6720e-02,  1.0673e-01],\n",
       "          [ 9.7871e-02,  9.5090e-03, -1.9436e-02],\n",
       "          [ 1.0383e-01, -9.6200e-02,  1.2835e-01]],\n",
       "\n",
       "         [[-1.6438e-02, -2.9095e-02,  1.2441e-01],\n",
       "          [ 4.5023e-02,  7.0098e-02,  6.9465e-03],\n",
       "          [-7.3581e-02,  5.2352e-02, -1.1486e-01]],\n",
       "\n",
       "         [[ 5.4501e-02, -1.5320e-02,  1.2374e-04],\n",
       "          [ 6.8916e-03, -8.5179e-02,  9.8272e-03],\n",
       "          [ 4.4572e-02,  5.5526e-02,  1.3761e-01]]]], requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "c = (a + b) / 2\n",
    "c = Variable(c)\n",
    "c.requires_grad=True\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "834b63c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,3,5,5)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70b61db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = torch.zeros(3)\n",
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2205095e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = functional.conv2d(x, c, bias, stride=1, padding=1)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0873380f",
   "metadata": {},
   "source": [
    "测试sequencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae0ba1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = torch.nn.Sequential(nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1, bias=False),\n",
    "                            nn.BatchNorm2d(3),\n",
    "                            nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1, bias=False))\n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "967f94bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.efficientnet_v2_s()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "40b31bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "      (1): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.005, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.01, mode=row)\n",
       "      )\n",
       "      (1): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.015000000000000003, mode=row)\n",
       "      )\n",
       "      (2): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.02, mode=row)\n",
       "      )\n",
       "      (3): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.030000000000000006, mode=row)\n",
       "      )\n",
       "      (1): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.035, mode=row)\n",
       "      )\n",
       "      (2): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.04, mode=row)\n",
       "      )\n",
       "      (3): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.045, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05500000000000001, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06000000000000001, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.065, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07, mode=row)\n",
       "      )\n",
       "      (5): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.075, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "            (1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.085, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.095, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (5): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.10500000000000001, mode=row)\n",
       "      )\n",
       "      (6): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.11000000000000001, mode=row)\n",
       "      )\n",
       "      (7): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.11500000000000002, mode=row)\n",
       "      )\n",
       "      (8): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.12000000000000002, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.13, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.135, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14500000000000002, mode=row)\n",
       "      )\n",
       "      (5): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15, mode=row)\n",
       "      )\n",
       "      (6): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.155, mode=row)\n",
       "      )\n",
       "      (7): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.16, mode=row)\n",
       "      )\n",
       "      (8): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.165, mode=row)\n",
       "      )\n",
       "      (9): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17, mode=row)\n",
       "      )\n",
       "      (10): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.175, mode=row)\n",
       "      )\n",
       "      (11): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.18, mode=row)\n",
       "      )\n",
       "      (12): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.185, mode=row)\n",
       "      )\n",
       "      (13): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.19, mode=row)\n",
       "      )\n",
       "      (14): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.195, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Conv2dNormActivation(\n",
       "      (0): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=True)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "17543d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d8148499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): FusedMBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(24, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.01, mode=row)\n",
       "  )\n",
       "  (1): FusedMBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.015000000000000003, mode=row)\n",
       "  )\n",
       "  (2): FusedMBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.02, mode=row)\n",
       "  )\n",
       "  (3): FusedMBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.features[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dd4b4968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.features[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8d015eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FusedMBConv(\n",
       "  (block): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Conv2dNormActivation(\n",
       "      (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (stochastic_depth): StochasticDepth(p=0.015000000000000003, mode=row)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.features[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8715e278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers1 = torch.nn.Sequential(nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1, bias=False),\n",
    "                            nn.BatchNorm2d(3),\n",
    "                            nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1, bias=False))\n",
    "layers2 = torch.nn.Sequential(nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1, bias=False),\n",
    "                            nn.BatchNorm2d(3),\n",
    "                            nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1, bias=False))\n",
    "layers2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3b0bce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[[[ 0.0804,  0.1209, -0.0205],\n",
       "                        [ 0.0005,  0.0665,  0.1233],\n",
       "                        [-0.0352, -0.0695,  0.0064]],\n",
       "              \n",
       "                       [[ 0.1561, -0.0747,  0.1415],\n",
       "                        [-0.1410,  0.0719, -0.0140],\n",
       "                        [-0.0071, -0.0655, -0.0447]],\n",
       "              \n",
       "                       [[ 0.0679,  0.1416,  0.1870],\n",
       "                        [-0.1270, -0.1289,  0.1186],\n",
       "                        [ 0.0553, -0.1193,  0.1104]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0786, -0.0536, -0.1099],\n",
       "                        [ 0.0004,  0.1109,  0.1834],\n",
       "                        [-0.0327,  0.0480, -0.1861]],\n",
       "              \n",
       "                       [[-0.0844, -0.0950, -0.1664],\n",
       "                        [ 0.0822, -0.0645,  0.1251],\n",
       "                        [-0.0187,  0.0977,  0.0022]],\n",
       "              \n",
       "                       [[ 0.1252,  0.0265,  0.1829],\n",
       "                        [-0.1279, -0.0319, -0.1012],\n",
       "                        [ 0.1060, -0.1084, -0.1089]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0724, -0.0670, -0.1007],\n",
       "                        [-0.0393, -0.1339,  0.0647],\n",
       "                        [-0.0165,  0.1625,  0.0369]],\n",
       "              \n",
       "                       [[ 0.0217,  0.0839,  0.0166],\n",
       "                        [-0.0189,  0.1228,  0.1907],\n",
       "                        [-0.0125, -0.1099,  0.0525]],\n",
       "              \n",
       "                       [[-0.0749, -0.1670, -0.0269],\n",
       "                        [ 0.0018, -0.1839, -0.1451],\n",
       "                        [-0.1647,  0.1737, -0.1705]]]])),\n",
       "             ('1.weight', tensor([1., 1., 1.])),\n",
       "             ('1.bias', tensor([0., 0., 0.])),\n",
       "             ('1.running_mean', tensor([0., 0., 0.])),\n",
       "             ('1.running_var', tensor([1., 1., 1.])),\n",
       "             ('1.num_batches_tracked', tensor(0)),\n",
       "             ('2.weight',\n",
       "              tensor([[[[ 0.0428, -0.1024,  0.0283],\n",
       "                        [-0.1318, -0.1535,  0.1572],\n",
       "                        [-0.1419,  0.1229, -0.1640]],\n",
       "              \n",
       "                       [[ 0.1426,  0.0403, -0.1799],\n",
       "                        [ 0.0687, -0.1622, -0.0862],\n",
       "                        [-0.1168,  0.1757, -0.0870]],\n",
       "              \n",
       "                       [[-0.0113, -0.0581, -0.0875],\n",
       "                        [ 0.0360, -0.0316, -0.0644],\n",
       "                        [-0.0563, -0.0620, -0.1304]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0606, -0.0245,  0.0080],\n",
       "                        [ 0.1349,  0.1413, -0.0616],\n",
       "                        [-0.0020, -0.1537, -0.1713]],\n",
       "              \n",
       "                       [[-0.1287,  0.0627,  0.1010],\n",
       "                        [ 0.0280,  0.1441,  0.0895],\n",
       "                        [ 0.1651, -0.1387,  0.0508]],\n",
       "              \n",
       "                       [[-0.0072,  0.0499,  0.1699],\n",
       "                        [-0.0390,  0.1430,  0.0649],\n",
       "                        [-0.0182, -0.0872,  0.1310]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1911,  0.0292,  0.0816],\n",
       "                        [ 0.1842,  0.1207,  0.1178],\n",
       "                        [ 0.0557,  0.1149,  0.0984]],\n",
       "              \n",
       "                       [[ 0.1396, -0.0530, -0.0011],\n",
       "                        [ 0.1397, -0.1188, -0.1339],\n",
       "                        [-0.1699, -0.0168, -0.0249]],\n",
       "              \n",
       "                       [[-0.0986,  0.0848,  0.1193],\n",
       "                        [ 0.0954,  0.0322, -0.0649],\n",
       "                        [ 0.0885,  0.1432, -0.0745]]]]))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9239709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[[[-0.0242, -0.1919, -0.1326],\n",
       "                        [-0.1720, -0.1863, -0.1205],\n",
       "                        [-0.1607,  0.0020,  0.1276]],\n",
       "              \n",
       "                       [[ 0.1180, -0.0572, -0.0044],\n",
       "                        [ 0.0319, -0.1746,  0.1193],\n",
       "                        [-0.0705,  0.1544,  0.1866]],\n",
       "              \n",
       "                       [[-0.0490,  0.0407,  0.1921],\n",
       "                        [ 0.1858,  0.1481,  0.1553],\n",
       "                        [-0.1286, -0.0533,  0.1309]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0246,  0.0983, -0.0317],\n",
       "                        [-0.1224,  0.1273, -0.1132],\n",
       "                        [ 0.0494, -0.0639, -0.1674]],\n",
       "              \n",
       "                       [[ 0.0634, -0.0706,  0.1228],\n",
       "                        [-0.0062,  0.0901, -0.1577],\n",
       "                        [ 0.1310,  0.0853, -0.0079]],\n",
       "              \n",
       "                       [[ 0.1724, -0.0497, -0.1303],\n",
       "                        [ 0.0922, -0.0878, -0.1633],\n",
       "                        [ 0.0289,  0.1049,  0.0597]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0206,  0.1608,  0.1461],\n",
       "                        [ 0.0087,  0.1467, -0.1349],\n",
       "                        [ 0.1341, -0.1715,  0.1073]],\n",
       "              \n",
       "                       [[-0.1486, -0.1464, -0.0490],\n",
       "                        [ 0.1524, -0.0902,  0.0662],\n",
       "                        [-0.1842, -0.1884,  0.1725]],\n",
       "              \n",
       "                       [[ 0.0940,  0.0625,  0.1132],\n",
       "                        [-0.0963, -0.1837,  0.1208],\n",
       "                        [ 0.0347,  0.1691,  0.0976]]]])),\n",
       "             ('1.weight', tensor([1., 1., 1.])),\n",
       "             ('1.bias', tensor([0., 0., 0.])),\n",
       "             ('1.running_mean', tensor([0., 0., 0.])),\n",
       "             ('1.running_var', tensor([1., 1., 1.])),\n",
       "             ('1.num_batches_tracked', tensor(0)),\n",
       "             ('2.weight',\n",
       "              tensor([[[[ 0.1479, -0.1750,  0.0385],\n",
       "                        [ 0.0264,  0.0729,  0.0716],\n",
       "                        [ 0.1330,  0.0751,  0.0067]],\n",
       "              \n",
       "                       [[-0.1411,  0.0937, -0.0955],\n",
       "                        [ 0.0413, -0.0771,  0.0984],\n",
       "                        [-0.1882, -0.0973,  0.1464]],\n",
       "              \n",
       "                       [[ 0.0297, -0.0625,  0.0100],\n",
       "                        [ 0.1075, -0.1678, -0.1001],\n",
       "                        [ 0.0459, -0.0566, -0.0601]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0860, -0.0543, -0.0205],\n",
       "                        [-0.0103,  0.0547,  0.1426],\n",
       "                        [ 0.1833, -0.0577,  0.0794]],\n",
       "              \n",
       "                       [[ 0.0450,  0.1090,  0.0671],\n",
       "                        [ 0.0186, -0.1879,  0.0630],\n",
       "                        [ 0.1614,  0.0275, -0.0953]],\n",
       "              \n",
       "                       [[-0.0898,  0.1174,  0.1518],\n",
       "                        [ 0.0523,  0.0026,  0.1202],\n",
       "                        [-0.0429, -0.0648, -0.0108]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0502, -0.1234,  0.1208],\n",
       "                        [ 0.0424,  0.0588,  0.0948],\n",
       "                        [-0.0841, -0.1444,  0.0283]],\n",
       "              \n",
       "                       [[-0.0936,  0.0960,  0.0175],\n",
       "                        [-0.0388,  0.0501,  0.1359],\n",
       "                        [ 0.1061,  0.0464,  0.0736]],\n",
       "              \n",
       "                       [[ 0.1862, -0.0310,  0.1073],\n",
       "                        [ 0.0712,  0.0097,  0.0973],\n",
       "                        [-0.1278, -0.0713,  0.0004]]]]))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22fa4387",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = layers1.state_dict()\n",
    "b = layers2.state_dict()\n",
    "c = layers.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e31e8770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[[[ 0.0261, -0.1427,  0.0538],\n",
       "                        [-0.0548,  0.1374,  0.0751],\n",
       "                        [-0.0847,  0.1487,  0.1235]],\n",
       "              \n",
       "                       [[-0.0438, -0.1285,  0.0451],\n",
       "                        [ 0.1478, -0.0203, -0.0695],\n",
       "                        [ 0.0942, -0.0340,  0.1376]],\n",
       "              \n",
       "                       [[-0.0518, -0.0011, -0.0732],\n",
       "                        [-0.0415, -0.1470, -0.0437],\n",
       "                        [ 0.1803,  0.0457,  0.1090]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0472,  0.0206, -0.0253],\n",
       "                        [-0.0961,  0.0096,  0.0516],\n",
       "                        [ 0.0164,  0.0795,  0.0694]],\n",
       "              \n",
       "                       [[-0.1107, -0.0778, -0.0783],\n",
       "                        [ 0.0272, -0.0560,  0.0170],\n",
       "                        [-0.1020,  0.0167,  0.0248]],\n",
       "              \n",
       "                       [[ 0.0937, -0.1231,  0.0391],\n",
       "                        [ 0.0333, -0.1237, -0.0120],\n",
       "                        [-0.1210, -0.0973, -0.0743]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0445, -0.0711,  0.0034],\n",
       "                        [ 0.0335,  0.0091,  0.0521],\n",
       "                        [-0.0435,  0.0602,  0.0670]],\n",
       "              \n",
       "                       [[-0.0271,  0.0742,  0.1389],\n",
       "                        [ 0.0739, -0.0531, -0.0960],\n",
       "                        [-0.0050,  0.0246,  0.0294]],\n",
       "              \n",
       "                       [[-0.0009, -0.0145, -0.0613],\n",
       "                        [-0.0912, -0.0577,  0.0231],\n",
       "                        [-0.1541,  0.0576, -0.0405]]]])),\n",
       "             ('1.weight', tensor([1., 1., 1.])),\n",
       "             ('1.bias', tensor([0., 0., 0.])),\n",
       "             ('1.running_mean', tensor([0., 0., 0.])),\n",
       "             ('1.running_var', tensor([1., 1., 1.])),\n",
       "             ('1.num_batches_tracked', tensor(0.)),\n",
       "             ('2.weight',\n",
       "              tensor([[[[-0.1455, -0.1168, -0.0769],\n",
       "                        [ 0.0501, -0.0141, -0.0343],\n",
       "                        [-0.0005,  0.0866, -0.0282]],\n",
       "              \n",
       "                       [[ 0.0149, -0.0481,  0.1004],\n",
       "                        [ 0.0237, -0.0524, -0.0458],\n",
       "                        [ 0.0756, -0.0679, -0.0224]],\n",
       "              \n",
       "                       [[-0.0178, -0.0379, -0.1478],\n",
       "                        [-0.0203,  0.0965, -0.0800],\n",
       "                        [ 0.1043, -0.0832, -0.1133]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0586,  0.0476, -0.1321],\n",
       "                        [ 0.0596,  0.1303,  0.0798],\n",
       "                        [ 0.0405, -0.0475, -0.1076]],\n",
       "              \n",
       "                       [[ 0.1292,  0.1060,  0.0029],\n",
       "                        [ 0.0560,  0.0301, -0.0366],\n",
       "                        [-0.0533, -0.0730,  0.0658]],\n",
       "              \n",
       "                       [[-0.1631, -0.0629, -0.0299],\n",
       "                        [ 0.0589, -0.1247,  0.0181],\n",
       "                        [-0.0323,  0.0595, -0.0439]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0394, -0.1311,  0.0622],\n",
       "                        [ 0.0520,  0.0473, -0.1291],\n",
       "                        [ 0.0636, -0.0692, -0.0599]],\n",
       "              \n",
       "                       [[ 0.0095,  0.0941,  0.1498],\n",
       "                        [ 0.0994, -0.0116,  0.0867],\n",
       "                        [-0.0477,  0.1030,  0.0576]],\n",
       "              \n",
       "                       [[ 0.1214, -0.1055,  0.0011],\n",
       "                        [-0.1820, -0.0098, -0.0187],\n",
       "                        [ 0.0117, -0.1796, -0.1085]]]]))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key, _ in c.items():\n",
    "    c[key] = (a[key] + b[key]) / 2\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "904b0e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0428, -0.1024,  0.0283],\n",
      "          [-0.1318, -0.1535,  0.1572],\n",
      "          [-0.1419,  0.1229, -0.1640]],\n",
      "\n",
      "         [[ 0.1426,  0.0403, -0.1799],\n",
      "          [ 0.0687, -0.1622, -0.0862],\n",
      "          [-0.1168,  0.1757, -0.0870]],\n",
      "\n",
      "         [[-0.0113, -0.0581, -0.0875],\n",
      "          [ 0.0360, -0.0316, -0.0644],\n",
      "          [-0.0563, -0.0620, -0.1304]]],\n",
      "\n",
      "\n",
      "        [[[-0.0606, -0.0245,  0.0080],\n",
      "          [ 0.1349,  0.1413, -0.0616],\n",
      "          [-0.0020, -0.1537, -0.1713]],\n",
      "\n",
      "         [[-0.1287,  0.0627,  0.1010],\n",
      "          [ 0.0280,  0.1441,  0.0895],\n",
      "          [ 0.1651, -0.1387,  0.0508]],\n",
      "\n",
      "         [[-0.0072,  0.0499,  0.1699],\n",
      "          [-0.0390,  0.1430,  0.0649],\n",
      "          [-0.0182, -0.0872,  0.1310]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1911,  0.0292,  0.0816],\n",
      "          [ 0.1842,  0.1207,  0.1178],\n",
      "          [ 0.0557,  0.1149,  0.0984]],\n",
      "\n",
      "         [[ 0.1396, -0.0530, -0.0011],\n",
      "          [ 0.1397, -0.1188, -0.1339],\n",
      "          [-0.1699, -0.0168, -0.0249]],\n",
      "\n",
      "         [[-0.0986,  0.0848,  0.1193],\n",
      "          [ 0.0954,  0.0322, -0.0649],\n",
      "          [ 0.0885,  0.1432, -0.0745]]]])\n",
      "2.weight\n"
     ]
    }
   ],
   "source": [
    "print(de)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3fa2392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1479, -0.1750,  0.0385],\n",
       "          [ 0.0264,  0.0729,  0.0716],\n",
       "          [ 0.1330,  0.0751,  0.0067]],\n",
       "\n",
       "         [[-0.1411,  0.0937, -0.0955],\n",
       "          [ 0.0413, -0.0771,  0.0984],\n",
       "          [-0.1882, -0.0973,  0.1464]],\n",
       "\n",
       "         [[ 0.0297, -0.0625,  0.0100],\n",
       "          [ 0.1075, -0.1678, -0.1001],\n",
       "          [ 0.0459, -0.0566, -0.0601]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0860, -0.0543, -0.0205],\n",
       "          [-0.0103,  0.0547,  0.1426],\n",
       "          [ 0.1833, -0.0577,  0.0794]],\n",
       "\n",
       "         [[ 0.0450,  0.1090,  0.0671],\n",
       "          [ 0.0186, -0.1879,  0.0630],\n",
       "          [ 0.1614,  0.0275, -0.0953]],\n",
       "\n",
       "         [[-0.0898,  0.1174,  0.1518],\n",
       "          [ 0.0523,  0.0026,  0.1202],\n",
       "          [-0.0429, -0.0648, -0.0108]]],\n",
       "\n",
       "\n",
       "        [[[-0.0502, -0.1234,  0.1208],\n",
       "          [ 0.0424,  0.0588,  0.0948],\n",
       "          [-0.0841, -0.1444,  0.0283]],\n",
       "\n",
       "         [[-0.0936,  0.0960,  0.0175],\n",
       "          [-0.0388,  0.0501,  0.1359],\n",
       "          [ 0.1061,  0.0464,  0.0736]],\n",
       "\n",
       "         [[ 0.1862, -0.0310,  0.1073],\n",
       "          [ 0.0712,  0.0097,  0.0973],\n",
       "          [-0.1278, -0.0713,  0.0004]]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b6865e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0953, -0.1387,  0.0334],\n",
       "          [-0.0527, -0.0403,  0.1144],\n",
       "          [-0.0045,  0.0990, -0.0786]],\n",
       "\n",
       "         [[ 0.0007,  0.0670, -0.1377],\n",
       "          [ 0.0550, -0.1196,  0.0061],\n",
       "          [-0.1525,  0.0392,  0.0297]],\n",
       "\n",
       "         [[ 0.0092, -0.0603, -0.0388],\n",
       "          [ 0.0717, -0.0997, -0.0823],\n",
       "          [-0.0052, -0.0593, -0.0952]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0127, -0.0394, -0.0062],\n",
       "          [ 0.0623,  0.0980,  0.0405],\n",
       "          [ 0.0907, -0.1057, -0.0459]],\n",
       "\n",
       "         [[-0.0418,  0.0858,  0.0841],\n",
       "          [ 0.0233, -0.0219,  0.0762],\n",
       "          [ 0.1633, -0.0556, -0.0223]],\n",
       "\n",
       "         [[-0.0485,  0.0837,  0.1609],\n",
       "          [ 0.0067,  0.0728,  0.0926],\n",
       "          [-0.0305, -0.0760,  0.0601]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0705, -0.0471,  0.1012],\n",
       "          [ 0.1133,  0.0898,  0.1063],\n",
       "          [-0.0142, -0.0147,  0.0634]],\n",
       "\n",
       "         [[ 0.0230,  0.0215,  0.0082],\n",
       "          [ 0.0505, -0.0344,  0.0010],\n",
       "          [-0.0319,  0.0148,  0.0243]],\n",
       "\n",
       "         [[ 0.0438,  0.0269,  0.1133],\n",
       "          [ 0.0833,  0.0210,  0.0162],\n",
       "          [-0.0197,  0.0360, -0.0370]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[df] = (a[df] + b[df]) / 2\n",
    "c[df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea60dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = torch.nn.Sequential(nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1, bias=False),\n",
    "                            nn.BatchNorm2d(3),\n",
    "                            nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1, bias=False),\n",
    "                            nn.AdaptiveAvgPool2d(1))\n",
    "linear = nn.Linear(3,2,bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab9d2d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers1 = torch.nn.Sequential(nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1, bias=False),\n",
    "                            nn.BatchNorm2d(3),\n",
    "                            nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1, bias=False),\n",
    "                            nn.AdaptiveAvgPool2d(1))\n",
    "layers2 = torch.nn.Sequential(nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1, bias=False),\n",
    "                            nn.BatchNorm2d(3),\n",
    "                            nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1, bias=False),\n",
    "                            nn.AdaptiveAvgPool2d(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb73bba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = layers1.state_dict()\n",
    "b = layers2.state_dict()\n",
    "c = layers.state_dict()\n",
    "\n",
    "for key, _ in c.items():\n",
    "    c[key] = (a[key] + b[key]) / 2\n",
    "\n",
    "layers1.load_state_dict(a)\n",
    "layers2.load_state_dict(b)\n",
    "layers.load_state_dict(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "361981a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5, 5])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,3,5,5)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c22b4839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0296,  0.0398],\n",
       "        [ 0.0060, -0.0063]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 = layers(x)\n",
    "out1 = out1.view(2,-1)\n",
    "linear(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc74cab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0149,  0.0388],\n",
       "        [ 0.0115, -0.0212]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 = layers1(x)\n",
    "out1 = out1.view(2,-1)\n",
    "linear(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59421997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0989,  0.0115],\n",
       "        [-0.0474,  0.0109]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1 = layers2(x)\n",
    "out1 = out1.view(2,-1)\n",
    "linear(out1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c18bee",
   "metadata": {},
   "source": [
    "测试模型集成代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5546bd5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "# x = torch.randn(3,2)\n",
    "# _, a = torch.max(x, dim=1)\n",
    "# print(a)\n",
    "\n",
    "# x = torch.randn(3,2)\n",
    "# _, b = torch.max(x, dim=1)\n",
    "# print(b)\n",
    "\n",
    "\n",
    "# x = torch.randn(3,2)\n",
    "# _, c = torch.max(x, dim=1)\n",
    "# print(c)\n",
    "\n",
    "# d = [a,b,c]\n",
    "# d = torch.stack(d,dim=1)\n",
    "# d = d.squeeze(1)\n",
    "# print(d.shape)\n",
    "\n",
    "x1 = torch.randn(3,2)\n",
    "x2 = torch.randn(3,2)\n",
    "x3 = torch.randn(3,2)\n",
    "d = [x1,x2,x3]\n",
    "d = torch.cat(d,1)\n",
    "print(d.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20680db0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28msum\u001b[39m(\u001b[43mc\u001b[49m[\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'c' is not defined"
     ]
    }
   ],
   "source": [
    "sum(c[0,:]==1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9eb49e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1., 2.]), tensor([1., 2.]), tensor([2., 1.])]\n"
     ]
    }
   ],
   "source": [
    "c_ = []\n",
    "for r in range(c.size(0)):\n",
    "    num_0 = sum(c[r,:]==0)\n",
    "    num_1 = sum(c[r,:]==1)\n",
    "    a = torch.randn(2)\n",
    "    a[0] = num_0\n",
    "    a[1] = num_1\n",
    "    c_.append(a)\n",
    "    \n",
    "print(c_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "252e0f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [1., 2.],\n",
      "        [2., 1.]])\n"
     ]
    }
   ],
   "source": [
    "d = torch.stack(c_,dim=0)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "43d94537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "_, e = torch.max(d, dim=1)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0c9be7",
   "metadata": {},
   "source": [
    "测试CBAM模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb482695",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAMLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 channel: int,\n",
    "                 reduction=4,\n",
    "                 spatial_kernel=7,\n",
    "                 activation = torch.nn.ReLU,\n",
    "                 scale_activation = torch.nn.Sigmoid,):\n",
    "        super(CBAMLayer, self).__init__()\n",
    "\n",
    "        # channel attention\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # shared MLP in channel attention\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Conv2d(channel, channel // reduction, 1, bias=False),    # 功能等同于全连接层\n",
    "            activation(),\n",
    "            nn.Conv2d(channel // reduction, channel, 1, bias=False)\n",
    "        )\n",
    "\n",
    "        # spatial attention\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=spatial_kernel, padding=spatial_kernel // 2, bias=False)\n",
    "        self.scale_activation = scale_activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 通道注意力\n",
    "        print(\"x:\",x.size())\n",
    "        max_out = self.mlp(self.max_pool(x))\n",
    "        print(\"max_out:\",max_out.size())\n",
    "        avg_out = self.mlp(self.avg_pool(x))\n",
    "        print(\"avg_out:\",avg_out.size())\n",
    "        channel_out = self.scale_activation(max_out + avg_out)\n",
    "        print(\"channel_out:\",channel_out.size())\n",
    "        x *= channel_out\n",
    "        print(\"x:\",x.size())\n",
    "\n",
    "        # 空间注意力\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        print(\"max_out:\",max_out.size())\n",
    "        avg_out, _ = torch.mean(x, dim=1, keepdim=True)\n",
    "        print(\"avg_out:\",avg_out.size())\n",
    "        spatial_out = self.scale_activation(self.conv(torch.cat([max_out, avg_out], dim=1)))\n",
    "        x *= spatial_out\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b028e96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 5, 5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2,4,5,5)\n",
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eee36d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([2, 4, 5, 5])\n",
      "max_out: torch.Size([2, 4, 1, 1])\n",
      "avg_out: torch.Size([2, 4, 1, 1])\n",
      "channel_out: torch.Size([2, 4, 1, 1])\n",
      "x: torch.Size([2, 4, 5, 5])\n",
      "max_out: torch.Size([2, 1, 5, 5])\n",
      "avg_out: torch.Size([1, 5, 5])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 4 and 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m cbam \u001b[38;5;241m=\u001b[39m CBAMLayer(\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mcbam\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m a\u001b[38;5;241m.\u001b[39msize()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mCBAMLayer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     40\u001b[0m avg_out, _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_out:\u001b[39m\u001b[38;5;124m\"\u001b[39m,avg_out\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m---> 42\u001b[0m spatial_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_activation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmax_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavg_out\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     43\u001b[0m x \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m spatial_out\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 4 and 3"
     ]
    }
   ],
   "source": [
    "cbam = CBAMLayer(4)\n",
    "a = cbam(a)\n",
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "036e8a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.8823, -2.1015],\n",
      "          [-1.5589,  0.0796]],\n",
      "\n",
      "         [[ 0.2767, -0.1671],\n",
      "          [ 2.7195, -0.5380]],\n",
      "\n",
      "         [[-0.5586,  0.0856],\n",
      "          [-1.4114, -0.1080]],\n",
      "\n",
      "         [[ 0.0236,  0.2704],\n",
      "          [-0.2852,  0.2097]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3468,  1.5255],\n",
      "          [-0.6913,  0.5706]],\n",
      "\n",
      "         [[ 0.0058, -0.1551],\n",
      "          [-0.2402,  0.5148]],\n",
      "\n",
      "         [[-0.5006,  0.6281],\n",
      "          [-2.2064,  1.4147]],\n",
      "\n",
      "         [[ 0.2465,  0.3509],\n",
      "          [ 0.0755, -0.4617]]]])\n",
      "tensor([[[[ 0.1560, -0.4782],\n",
      "          [-0.1340, -0.0892]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0246,  0.5873],\n",
      "          [-0.7656,  0.5096]]]])\n",
      "avg_out: torch.Size([2, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,4,2,2)\n",
    "print(a)\n",
    "avg_out = torch.mean(a, dim=1, keepdim=True)\n",
    "print(avg_out)\n",
    "print(\"avg_out:\",avg_out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b592c7b",
   "metadata": {},
   "source": [
    "去掉全连接层（fc层）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c943fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1280, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.efficientnet_v2_s()\n",
    "model.classifier[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0812ca92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): LeakyReLU(negative_slope=1)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc = nn.LeakyReLU(1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa15484a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5174,  0.5121],\n",
       "        [-0.5119,  0.2928],\n",
       "        [-0.4977, -1.2400]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3,2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6a3b5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5174,  0.5121],\n",
       "        [-0.0051,  0.2928],\n",
       "        [-0.0050, -0.0124]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac = nn.LeakyReLU()\n",
    "ac(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "865dce24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5174,  0.5121],\n",
       "        [-0.5119,  0.2928],\n",
       "        [-0.4977, -1.2400]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac = nn.LeakyReLU(1)\n",
    "ac(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51ee6717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2048])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 好像成了\n",
    "img = torch.randn(2,3,224,224)\n",
    "out = model(img)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb483eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "            \n",
    "class resnet_ensembling(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        weak_learner: Callable[..., nn.Module],\n",
    "        fc_length: int = 2048,\n",
    "        class_num: int = 2,\n",
    "    ) -> None:\n",
    "        self.model_num = len(weak_learner)\n",
    "        self.models = []\n",
    "        for model in weak_learner:\n",
    "            model.fc = nn.LeakyReLU(1)\n",
    "            set_parameter_requires_grad(model, True)\n",
    "            self.models.append(model)\n",
    "        self.combination = nn.Linear(model_num * fc_length, class_num)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        feature = []\n",
    "        for model in self.models:\n",
    "            out = model(x)\n",
    "            feature.append(out)\n",
    "        feature = troch.cat(feature, 1)\n",
    "        feature = self.bn(feature)\n",
    "        feature = self.combination(feature)\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aae7740",
   "metadata": {},
   "source": [
    "测试encoder层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76a33ce8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "was expecting embedding dimension of 512, but got 2048",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m ln \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLayerNorm(\u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m      3\u001b[0m src \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m2048\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m out\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:463\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 463\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    464\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:471\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[1;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[0;32m    470\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 471\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1153\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[0;32m   1142\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1143\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1150\u001b[0m         q_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj_weight, k_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj_weight,\n\u001b[0;32m   1151\u001b[0m         v_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj_weight, average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights)\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1153\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:5046\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)\u001b[0m\n\u001b[0;32m   5044\u001b[0m tgt_len, bsz, embed_dim \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   5045\u001b[0m src_len, _, _ \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m-> 5046\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m embed_dim \u001b[38;5;241m==\u001b[39m embed_dim_to_check, \\\n\u001b[0;32m   5047\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwas expecting embedding dimension of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membed_dim_to_check\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membed_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embed_dim, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m   5049\u001b[0m     \u001b[38;5;66;03m# embed_dim can be a tensor when JIT tracing\u001b[39;00m\n\u001b[0;32m   5050\u001b[0m     head_dim \u001b[38;5;241m=\u001b[39m embed_dim\u001b[38;5;241m.\u001b[39mdiv(num_heads, rounding_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrunc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: was expecting embedding dimension of 512, but got 2048"
     ]
    }
   ],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "ln = nn.LayerNorm(256)\n",
    "src = torch.rand(10, 2048)\n",
    "out = encoder_layer(src)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1657de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 24, 256])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.rand(2, 6144)\n",
    "src = src.view(2, -1, 256)\n",
    "src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4b2cdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 24, 256])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(d_model=256, nhead=8)\n",
    "out = encoder_layer(src)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b9f6cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 24, 256])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = ln(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a9b7840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6144])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = out.view(2,-1)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25c3db07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a333bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2,1,3)\n",
    "b = torch.randn(2,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d26da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.cat((a,b),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "750015a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c08f2ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet101()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "200e46c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29992b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Bottleneck(\n",
       "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (downsample): Sequential(\n",
       "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (1): Bottleneck(\n",
       "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (2): Bottleneck(\n",
       "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e2ff8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46ee9bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3, 4]\n",
    "b = list(range(len(a)))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb69ada7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3333333333333335"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd50f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2, bias=False),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64d50cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-1].in_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a6b3fa",
   "metadata": {},
   "source": [
    "测试张量拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00b462a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(64,2)\n",
    "b = torch.randn(64,2)\n",
    "b = a + b\n",
    "\n",
    "c = torch.cat([a,b], dim=0)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2eac129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1.]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(1,1,2,8)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be41fb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[2.8284],\n",
       "          [2.8284]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.norm(dim=-1, keepdim=True, p=2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "463c4390",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ([1,2,1,2,1,2])\n",
    "b = ([1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1b0da59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 2, 1, 2]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b7abdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.shape =  torch.Size([3, 5])\n",
      "target.shape =  torch.Size([3])\n",
      "tensor([1, 0, 1])\n",
      "input.shape =  torch.Size([3, 5])\n",
      "target.shape =  torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Example of target with class indices\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "print('input.shape = ', input.shape)\n",
    "target = torch.randint(5, (3,), dtype=torch.int64)\n",
    "print('target.shape = ', target.shape)\n",
    "print(target)\n",
    "loss = F.cross_entropy(input, target)\n",
    "loss.backward()\n",
    "\n",
    "# Example of target with class probabilities\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "print('input.shape = ', input.shape)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "print('target.shape = ', target.shape)\n",
    "loss = F.cross_entropy(input, target)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b9fe918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n",
      "tensor([-0.9327,  0.1915,  0.0873, -0.0388, -1.5158, -0.9315, -0.2085, -1.7000,\n",
      "         0.0559,  0.5599, -0.2764,  1.1807, -0.4583, -0.0987,  0.5731, -0.6555,\n",
      "         2.8229, -0.5123,  1.5649, -0.1747,  0.2019,  0.9617,  0.9766,  0.9996,\n",
      "         0.5662, -2.3061, -0.3973,  0.0641, -0.3041,  1.0716,  0.5142,  0.4007,\n",
      "        -1.4754,  0.8498, -0.4011,  0.3414, -0.7452, -0.9229, -0.7684,  0.1977,\n",
      "        -0.3378,  2.4418,  0.6940, -0.5529, -1.3869, -1.2504,  0.7955, -0.0593,\n",
      "        -0.4837,  0.7927, -1.4871,  0.1763,  0.7193,  0.9425, -0.2407, -0.1577,\n",
      "        -1.4671,  0.5832, -0.4333,  0.4288, -0.7244, -0.6726,  2.0173,  0.2645])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(64)\n",
    "b = torch.randn(64)\n",
    "print(a.shape)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38d49c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 2])\n",
      "tensor([ 0.1849, -0.9327])\n"
     ]
    }
   ],
   "source": [
    "out = torch.stack((a, b), dim = 1)\n",
    "print(out.shape)\n",
    "print(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a0dc7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(64)\n",
    "b = torch.ones(a.shape)\n",
    "print(b.shape)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "217c6409",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute '__next__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m myiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(dataloader)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# print(dir(dataloader))\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__next__\u001b[39;49m())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute '__next__'"
     ]
    }
   ],
   "source": [
    "class MyDataloader:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        self.count += 1\n",
    "        str = '*'*(2 * self.count - 1)\n",
    "        if self.count >= 3:\n",
    "            raise StopIteration\n",
    "        return str\n",
    "        \n",
    "dataloader = MyDataloader()\n",
    "myiter = iter(dataloader)\n",
    "# print(dir(dataloader))\n",
    "\n",
    "print(it.__next__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcb97a25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "class MyNumbers:\n",
    "    def __iter__(self):\n",
    "        self.a = 1\n",
    "        return self\n",
    " \n",
    "    def __next__(self):\n",
    "        if self.a <= 20:\n",
    "            x = self.a\n",
    "            self.a += 1\n",
    "            return x\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "myclass = MyNumbers()\n",
    "myiter = iter(myclass)\n",
    " \n",
    "for x in myiter:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed49e6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "tensor([2, 1, 4, 3, 5, 0])\n",
      "tensor([[ 9,  8, 11],\n",
      "        [10, 12,  7]])\n"
     ]
    }
   ],
   "source": [
    "t=torch.tensor([[7, 8, 9],[10, 11, 12]])\n",
    "print(t.nelement())\n",
    "idx = torch.randperm(t.nelement())\n",
    "print(idx)\n",
    "# t = t.view(-1)[idx]\n",
    "t = t.view(-1)[idx].view(t.size())\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a2e6cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "t=torch.tensor([[1, 2, 3],[3, 4, 5]])\n",
    "print(t.shape)\n",
    "idx = torch.randperm(t.shape[1])\n",
    "t = t[:, idx].view(t.size())\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea7df395",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataloader:\n",
    "    def __init__(self, pytorchDataloader, batchSize, shuffle=False, device='cpu'):\n",
    "        # sample功能考虑以后再做\n",
    "        # 要求pytorchDataloader的batchSize等于其数据量\n",
    "        self.iterNum = None\n",
    "        for item in pytorchDataloader:\n",
    "            self.data = item\n",
    "        self.data = self.data.to(device)\n",
    "        self.dataNum = self.data.shape[0]\n",
    "        self.batchSize = batchSize\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self.iterNum = 0\n",
    "        self.maxIterNum = self.dataNum // self.batchSize\n",
    "        if self.dataNum % self.batchSize > 0:\n",
    "            self.mod = 1\n",
    "        else:\n",
    "            self.mod = 0\n",
    "        if self.shuffle:\n",
    "            self.shuffleList = torch.randperm(self.dataNum)\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.iterNum >= self.maxIterNum + self.mod:\n",
    "            raise StopIteration\n",
    "        self.iterNum += 1\n",
    "        startIdx = (self.iterNum - 1) * self.batchSize\n",
    "        endIdx = min(self.iterNum * self.batchSize, self.dataNum)\n",
    "        if self.shuffle:\n",
    "            return self.data[self.shuffleList[startIdx:endIdx]]\n",
    "        else:\n",
    "            return self.data[startIdx:endIdx]\n",
    "    \n",
    "    def initGetData(self):\n",
    "        self.__iter__()\n",
    "        return\n",
    "    \n",
    "    def getNextData(self):\n",
    "        # 超出界限的数据不要了\n",
    "        if self.iterNum >= self.maxIterNum:\n",
    "            self.iterNum = 0\n",
    "        return self.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ad39649b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 6])\n",
      "tensor([[2, 2, 2, 2, 2, 2]], device='cuda:0')\n",
      "tensor([[3, 3, 3, 2, 2, 2]], device='cuda:0')\n",
      "tensor([[3, 3, 3, 2, 2, 2]], device='cuda:0')\n",
      "tensor([[2, 2, 2, 2, 2, 2]], device='cuda:0')\n",
      "tensor([[4, 4, 4, 2, 2, 2]], device='cuda:0')\n",
      "tensor([[1, 1, 1, 1, 1, 1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "t=torch.tensor([[[1, 1, 1, 1, 1, 1], [2, 2, 2, 2, 2, 2], [3, 3, 3, 2, 2, 2], [4, 4, 4, 2, 2, 2]]])\n",
    "print(t.shape)\n",
    "dataLoader = MyDataloader(t, 1, shuffle=True)\n",
    "\n",
    "dataLoader.initGetData()\n",
    "for n in range(2):\n",
    "    print(dataLoader.getNextData())\n",
    "    \n",
    "for i in dataLoader:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "011d0243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 64, 64])\n",
      "torch.Size([64, 3, 64, 64])\n",
      "torch.Size([64, 3, 64, 64])\n",
      "torch.Size([64, 3, 64, 64])\n",
      "torch.Size([64, 3, 64, 64])\n",
      "torch.Size([64, 3, 64, 64])\n",
      "torch.Size([64, 3, 64, 64])\n",
      "torch.Size([64, 3, 64, 64])\n",
      "torch.Size([64, 3, 64, 64])\n",
      "torch.Size([64, 3, 64, 64])\n",
      "torch.Size([2, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "dataLoader = MyDataloader(torch.randn(1,642,3,64,64), 64)\n",
    "for i in dataLoader:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ff00ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(64, 2)\n",
    "_, preds = torch.max(a, 1)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137429a8",
   "metadata": {},
   "source": [
    "SCConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "30efd082",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRU(nn.Module):\n",
    "    def __init__(self,\n",
    "                 oup_channels:int, \n",
    "                 group_num:int = 16,\n",
    "#                  gate_treshold:float = 0.5,\n",
    "                 torch_gn:bool = True\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # GroupNorm layerNorm的简化版，将通道C划分为若干组，在每组内执行layerNorm\n",
    "        self.gn             = nn.GroupNorm( num_channels = oup_channels, num_groups = group_num ) if torch_gn else GroupBatchnorm2d(c_num = oup_channels, group_num = group_num)\n",
    "#         self.gate_treshold  = gate_treshold\n",
    "        self.sigomid        = nn.Sigmoid()\n",
    "        self.advavg = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        B = x.shape[0]\n",
    "        gn_x        = self.gn(x)\n",
    "        print('gn_x', gn_x.shape)\n",
    "        w_gamma     = self.gn.weight/sum(self.gn.weight) # w_gamma为GroupNorm内的一个可训练参数，该数越大像素值变化越大，表明信息越丰富\n",
    "#         print(self.gn.weight.shape, sum(self.gn.weight).item(), w_gamma.shape)\n",
    "        w_gamma     = w_gamma.view(1,-1,1,1) # shape为1，C，1，1\n",
    "        reweigts    = self.sigomid( gn_x * w_gamma )\n",
    "        print('reweigts', reweigts.shape)\n",
    "        # Gate\n",
    "        gate_treshold = self.advavg(reweigts)\n",
    "        print('gate_treshold', gate_treshold.shape)\n",
    "        \n",
    "        w1          = torch.where(reweigts > gate_treshold, torch.ones_like(reweigts), reweigts) # 大于门限值的设为1，否则保留原值\n",
    "        w2          = torch.where(reweigts > gate_treshold, torch.zeros_like(reweigts), reweigts) # 大于门限值的设为0，否则保留原值\n",
    "        print('w1', w1.shape)\n",
    "        print('w2', w2.shape)\n",
    "        x_1         = w1 * x\n",
    "        x_2         = w2 * x\n",
    "        print('x_1', w1.shape)\n",
    "        print('x_2', w2.shape)\n",
    "        y           = self.reconstruct(x_1,x_2)\n",
    "        return y\n",
    "    \n",
    "    def reconstruct(self,x_1,x_2):\n",
    "        x_11,x_12 = torch.split(x_1, x_1.size(1)//2, dim=1)\n",
    "        x_21,x_22 = torch.split(x_2, x_2.size(1)//2, dim=1)\n",
    "        return torch.cat([ x_11+x_22, x_12+x_21 ],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8c16d61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gn_x torch.Size([1, 32, 14, 14])\n",
      "reweigts torch.Size([1, 32, 14, 14])\n",
      "gate_treshold torch.Size([1, 32, 1, 1])\n",
      "w1 torch.Size([1, 32, 14, 14])\n",
      "w2 torch.Size([1, 32, 14, 14])\n",
      "x_1 torch.Size([1, 32, 14, 14])\n",
      "x_2 torch.Size([1, 32, 14, 14])\n",
      "torch.Size([1, 32, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1, 32, 14, 14)\n",
    "module = SRU(32)\n",
    "a = module(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75578b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRU(nn.Module):\n",
    "    '''\n",
    "    alpha: 0<alpha<1\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_channel: int,\n",
    "                 op_channel: int,\n",
    "#                  alpha: float = 1 / 2,\n",
    "#                  squeeze_radio: int = 2,\n",
    "                 group_size: int = 2,\n",
    "                 group_kernel_size: int = 3,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        assert input_channel >= op_channel, '非降维'\n",
    "        assert input_channel % 2 == 0, '输入通道非偶数'\n",
    "        alpha = 0.5\n",
    "        squeeze_radio = 2\n",
    "        self.up_channel = up_channel = int(alpha * input_channel)\n",
    "        self.low_channel = low_channel = input_channel - up_channel\n",
    "        print(up_channel, low_channel)\n",
    "        self.squeeze1 = nn.Conv2d(up_channel, up_channel // squeeze_radio, kernel_size=1, bias=False)\n",
    "        self.squeeze2 = nn.Conv2d(low_channel, low_channel // squeeze_radio, kernel_size=1, bias=False)\n",
    "        print(up_channel // squeeze_radio, low_channel // squeeze_radio)\n",
    "        # up\n",
    "        self.GWC = nn.Conv2d(up_channel // squeeze_radio, op_channel, kernel_size=group_kernel_size, stride=1,\n",
    "                             padding=group_kernel_size // 2, groups=group_size)\n",
    "#         self.PWC1 = nn.Conv2d(up_channel // squeeze_radio, op_channel, kernel_size=1, bias=False)\n",
    "#         # low\n",
    "#         self.PWC2 = nn.Conv2d(low_channel // squeeze_radio, op_channel - low_channel // squeeze_radio, kernel_size=1,\n",
    "#                               bias=False)\n",
    "\n",
    "        self.DWC = nn.Conv2d(up_channel // squeeze_radio, op_channel, kernel_size=group_kernel_size, groups=(up_channel // squeeze_radio), padding=group_kernel_size // 2)\n",
    "        self.PWC = nn.Conv2d(low_channel // squeeze_radio, op_channel - low_channel // squeeze_radio, kernel_size=1, bias=False)\n",
    "        print(op_channel - low_channel // squeeze_radio)\n",
    "        self.advavg = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Split\n",
    "        up, low = torch.split(x, [self.up_channel, self.low_channel], dim=1)\n",
    "        up, low = self.squeeze1(up), self.squeeze2(low)\n",
    "        # Transform\n",
    "        Y1 = self.GWC(up) + self.DWC(up)\n",
    "        Y2 = torch.cat([self.PWC(low), low], dim=1)\n",
    "        # Fuse\n",
    "        out = torch.cat([Y1, Y2], dim=1)\n",
    "        out = functional.softmax(self.advavg(out), dim=1) * out\n",
    "        \n",
    "        out1, out2 = torch.split(out, out.size(1) // 2, dim=1)\n",
    "        return out1 + out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "929a3293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 16\n",
      "8 8\n",
      "24\n",
      "tensor([-0.0923, -0.3863,  0.0358,  0.3205, -0.0901,  0.0714,  0.3079,  0.0876,\n",
      "         0.2239,  0.3405,  0.1768, -0.1863, -0.1733,  0.3027,  0.4154, -0.2898,\n",
      "         0.0765, -0.0379,  0.2733,  0.0724, -0.3568,  0.2389,  0.1066,  0.3414,\n",
      "         0.2144,  0.3855,  0.1485,  0.1253, -0.1116, -0.1964, -0.3980, -0.1477,\n",
      "        -0.0100,  0.0112,  0.0231,  0.0059,  0.0110, -0.0137,  0.0181, -0.0044,\n",
      "         0.0162, -0.0067,  0.0259,  0.0243, -0.0130, -0.0726,  0.0037,  0.0213,\n",
      "        -0.0060,  0.0174, -0.0509,  0.0227,  0.0331,  0.0136, -0.0220, -0.0054,\n",
      "        -0.0205,  0.0564, -0.0824, -0.0462,  0.0087, -0.0628, -0.0092, -0.0393],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "torch.Size([1, 32, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1, 32, 14, 14)\n",
    "module = CRU(32, 32)\n",
    "a = module(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "02d48d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 2, 2])\n",
      "torch.Size([1, 2, 1, 1])\n",
      "tensor([[[[0., 2.],\n",
      "          [2., 2.]],\n",
      "\n",
      "         [[0., 3.],\n",
      "          [0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[[[1., 2.], [2., 2.]], [[2., 3.], [2., 2.]]]])\n",
    "advavg = nn.AdaptiveAvgPool2d(1)\n",
    "b = advavg(a)\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "\n",
    "out = torch.where(a > b, a, torch.zeros_like(a))\n",
    "print(out)\n",
    "\n",
    "# out = torch.where(a > c, torch.ones_like(a), -2)\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d241e3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
